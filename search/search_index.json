{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Illuminate Data is like garbage. You\u2019d better know what you are going to do with it before you collect it. \u2014 Mark Twain This code aims to be a thin, \"batteries included\", ETL framework. It is written using prominent Python frameworks such as Alembic , Click , Tornado and SQLAlchemy . Driver behind this project was a need for a rapid ETL and Scraping capabilities framework that is both development and deployment friendly, as well as something to return to the community. The whole idea is heavily influenced by django and Scrapy . Tested with pytest with a help of tox . Installation Package is provided by PyPI. For this occasion, we will create an example project, simply called \"tutorial\", that will use an example from project files. In your shell, type the following: mkdir tutorial cd tutorial python3 -m venv venv source venv/bin/activate pip install beautifulsoup4 illuminated NOTE : Package name on PyPI is illuminated . Illuminate is not dependent on beautifulsoup4 , but this example is. If installation is successful, you can verify by typing: illuminate --version NOTE : From version 0.3.5 on, the required SQLAlchemy version is 2.0.37 and above. Project Setup Once you have CLI ready to create a project structure in the current directory, type the following: export ILLUMINATE_MAIN_DB_PASSWORD = <DB_PASSWORD> export ILLUMINATE_MEASUREMENTS_DB_PASSWORD = <MEASUREMENTS_DB_PASSWORD> illuminate manage project setup tutorial . This will create a complete project structure with all the files and ENV vars needed to run the example ETL flow. Use the provided docker-compose.yaml file and bring the environment up. docker-compose up -d Once postgres and pgadmin containers are ready, you should perform database migration by creating a revision file and use it to upgrade the database, thus creating a table representing ExampleModel provided with the project files. illuminate manage db revision illuminate manage db upgrade This will create a table in the database that will be used as a Load destination for our example. Execution Now everything is set for Illuminate to start observing. illuminate observe start Docker distribution Illuminate is provided as containerized distribution as well: docker pull nikolamilojica/illuminate:latest To use docker distribution while inside a project directory, type the following: docker run -it --rm --network = host \\ -e ILLUMINATE_MAIN_DB_PASSWORD = <DB_PASSWORD> \\ -e ILLUMINATE_MEASUREMENTS_DB_PASSWORD = <MEASUREMENTS_DB_PASSWORD> \\ -v $( pwd ) :/home/illuminate \\ nikolamilojica/illuminate illuminate observe start","title":"Illuminate"},{"location":"#illuminate","text":"Data is like garbage. You\u2019d better know what you are going to do with it before you collect it. \u2014 Mark Twain This code aims to be a thin, \"batteries included\", ETL framework. It is written using prominent Python frameworks such as Alembic , Click , Tornado and SQLAlchemy . Driver behind this project was a need for a rapid ETL and Scraping capabilities framework that is both development and deployment friendly, as well as something to return to the community. The whole idea is heavily influenced by django and Scrapy . Tested with pytest with a help of tox .","title":"Illuminate"},{"location":"#installation","text":"Package is provided by PyPI. For this occasion, we will create an example project, simply called \"tutorial\", that will use an example from project files. In your shell, type the following: mkdir tutorial cd tutorial python3 -m venv venv source venv/bin/activate pip install beautifulsoup4 illuminated NOTE : Package name on PyPI is illuminated . Illuminate is not dependent on beautifulsoup4 , but this example is. If installation is successful, you can verify by typing: illuminate --version NOTE : From version 0.3.5 on, the required SQLAlchemy version is 2.0.37 and above.","title":"Installation"},{"location":"#project-setup","text":"Once you have CLI ready to create a project structure in the current directory, type the following: export ILLUMINATE_MAIN_DB_PASSWORD = <DB_PASSWORD> export ILLUMINATE_MEASUREMENTS_DB_PASSWORD = <MEASUREMENTS_DB_PASSWORD> illuminate manage project setup tutorial . This will create a complete project structure with all the files and ENV vars needed to run the example ETL flow. Use the provided docker-compose.yaml file and bring the environment up. docker-compose up -d Once postgres and pgadmin containers are ready, you should perform database migration by creating a revision file and use it to upgrade the database, thus creating a table representing ExampleModel provided with the project files. illuminate manage db revision illuminate manage db upgrade This will create a table in the database that will be used as a Load destination for our example.","title":"Project Setup"},{"location":"#execution","text":"Now everything is set for Illuminate to start observing. illuminate observe start","title":"Execution"},{"location":"#docker-distribution","text":"Illuminate is provided as containerized distribution as well: docker pull nikolamilojica/illuminate:latest To use docker distribution while inside a project directory, type the following: docker run -it --rm --network = host \\ -e ILLUMINATE_MAIN_DB_PASSWORD = <DB_PASSWORD> \\ -e ILLUMINATE_MEASUREMENTS_DB_PASSWORD = <MEASUREMENTS_DB_PASSWORD> \\ -v $( pwd ) :/home/illuminate \\ nikolamilojica/illuminate illuminate observe start","title":"Docker distribution"},{"location":"commands/","text":"Illuminate is run from shell. illuminate --help Usage: illuminate [OPTIONS] COMMAND [ARGS]... Framework entrypoint. Options: --version Show the version and exit. --verbosity [TRACE|DEBUG|INFO|SUCCESS|WARNING|ERROR|CRITICAL] Configure logging levels. [default: INFO] --help Show this message and exit. Commands: manage Framework manage group of commands. observe Framework observe group of commands. illuminate version illuminate, version 0.2.0 There are two types of command groups. manage and observe . manage illuminate manage --help Usage: illuminate manage [OPTIONS] COMMAND [ARGS]... Framework manage group of commands. Options: --help Show this message and exit. Commands: db Prepares relational db for ETL operations. project Performs project operations. project illuminate manage project --help Usage: illuminate manage project [OPTIONS] COMMAND [ARGS]... Performs project operations. Options: --help Show this message and exit. Commands: setup Creates a project directory with all needed files. setup illuminate manage project setup --help Usage: illuminate manage project setup [OPTIONS] NAME [PATH] Creates a project directory with all needed files. Options: --help Show this message and exit. arguments description default required NAME project name N/A True [PATH] project path current directory False db illuminate manage db --help Usage: illuminate manage db [OPTIONS] COMMAND [ARGS]... Prepares relational db for ETL operations. Options: --help Show this message and exit. Commands: populate Populates database with fixtures. revision Creates Alembic's revision file in migration directory. upgrade Applies migration file to a database. revision illuminate manage db revision --help Usage: illuminate manage db revision [OPTIONS] [PATH] Creates Alembic's revision file in migration directory. Options: --revision TEXT Alembic revision selector. [default: head] --selector TEXT Database connection selector. [default: main] --url TEXT Optional URL for databases not included in settings module. --help Show this message and exit. arguments description default required [PATH] project path current directory False upgrade illuminate manage db upgrade --help Usage: illuminate manage db upgrade [OPTIONS] [PATH] Applies migration file to a database. Options: --revision TEXT Alembic revision selector. [default: head] --selector TEXT Database connection selector. [default: main] --url TEXT Optional URL for databases not included in settings module. --help Show this message and exit arguments description default required [PATH] project path current directory False populate illuminate manage db populate --help Usage: illuminate manage db populate [OPTIONS] Populates database with fixtures. Options: --fixtures PATH Fixture files paths. [required] --selector TEXT Database connection selector. [default: main] --url TEXT Optional URL for databases not included in settings module. --help Show this message and exit. observe illuminate observe --help Usage: illuminate observe [OPTIONS] COMMAND [ARGS]... Framework observe group of commands. Options: --help Show this message and exit. Commands: catalogue Lists observers found in project files. start Starts producer/consumer ETL process. catalogue illuminate observe catalogue --help Usage: illuminate observe catalogue [OPTIONS] Lists observers found in project files. Options: --label TEXT Label selector in key=value format. --help Show this message and exit. start illuminate observe start --help Usage: illuminate observe start [OPTIONS] Starts producer/consumer ETL process. Options: --label TEXT Label selector in key=value format. --observer TEXT Observer selector. Leave empty to include all observers. --help Show this message and exit.","title":"Commands"},{"location":"commands/#manage","text":"illuminate manage --help Usage: illuminate manage [OPTIONS] COMMAND [ARGS]... Framework manage group of commands. Options: --help Show this message and exit. Commands: db Prepares relational db for ETL operations. project Performs project operations.","title":"manage"},{"location":"commands/#project","text":"illuminate manage project --help Usage: illuminate manage project [OPTIONS] COMMAND [ARGS]... Performs project operations. Options: --help Show this message and exit. Commands: setup Creates a project directory with all needed files.","title":"project"},{"location":"commands/#setup","text":"illuminate manage project setup --help Usage: illuminate manage project setup [OPTIONS] NAME [PATH] Creates a project directory with all needed files. Options: --help Show this message and exit. arguments description default required NAME project name N/A True [PATH] project path current directory False","title":"setup"},{"location":"commands/#db","text":"illuminate manage db --help Usage: illuminate manage db [OPTIONS] COMMAND [ARGS]... Prepares relational db for ETL operations. Options: --help Show this message and exit. Commands: populate Populates database with fixtures. revision Creates Alembic's revision file in migration directory. upgrade Applies migration file to a database.","title":"db"},{"location":"commands/#revision","text":"illuminate manage db revision --help Usage: illuminate manage db revision [OPTIONS] [PATH] Creates Alembic's revision file in migration directory. Options: --revision TEXT Alembic revision selector. [default: head] --selector TEXT Database connection selector. [default: main] --url TEXT Optional URL for databases not included in settings module. --help Show this message and exit. arguments description default required [PATH] project path current directory False","title":"revision"},{"location":"commands/#upgrade","text":"illuminate manage db upgrade --help Usage: illuminate manage db upgrade [OPTIONS] [PATH] Applies migration file to a database. Options: --revision TEXT Alembic revision selector. [default: head] --selector TEXT Database connection selector. [default: main] --url TEXT Optional URL for databases not included in settings module. --help Show this message and exit arguments description default required [PATH] project path current directory False","title":"upgrade"},{"location":"commands/#populate","text":"illuminate manage db populate --help Usage: illuminate manage db populate [OPTIONS] Populates database with fixtures. Options: --fixtures PATH Fixture files paths. [required] --selector TEXT Database connection selector. [default: main] --url TEXT Optional URL for databases not included in settings module. --help Show this message and exit.","title":"populate"},{"location":"commands/#observe","text":"illuminate observe --help Usage: illuminate observe [OPTIONS] COMMAND [ARGS]... Framework observe group of commands. Options: --help Show this message and exit. Commands: catalogue Lists observers found in project files. start Starts producer/consumer ETL process.","title":"observe"},{"location":"commands/#catalogue","text":"illuminate observe catalogue --help Usage: illuminate observe catalogue [OPTIONS] Lists observers found in project files. Options: --label TEXT Label selector in key=value format. --help Show this message and exit.","title":"catalogue"},{"location":"commands/#start","text":"illuminate observe start --help Usage: illuminate observe start [OPTIONS] Starts producer/consumer ETL process. Options: --label TEXT Label selector in key=value format. --observer TEXT Observer selector. Leave empty to include all observers. --help Show this message and exit.","title":"start"},{"location":"core/","text":"illuminate.manager.assistant.Assistant ( IAssistant ) Assistant class, creates objects from project files. Used by Manager class in its static methods and cli start function to initialize Manager. Source code in illuminate/manager/assistant.py class Assistant ( IAssistant ): \"\"\" Assistant class, creates objects from project files. Used by Manager class in its static methods and cli start function to initialize Manager. \"\"\" @staticmethod def provide_alembic_config ( path : str , selector : str , url : Optional [ str ] = None ) -> Config : \"\"\" Creates Alembic's configuration object. :param path: Migration directory path :param selector: Database name in settings.py module DB attribute :param url: SQLAlchemy Database URL :return: Alembic configuration object \"\"\" if not url : url = Assistant . _provide_db_url ( selector ) config = Config () config . set_main_option ( \"script_location\" , os . path . join ( path , \"migrations\" ) ) config . set_main_option ( \"sqlalchemy.url\" , url ) return config @staticmethod def provide_alembic_operations ( selector : str , url : Optional [ str ] = None ) -> Operations : \"\"\" Creates Alembic's operations object. NOTE: Currently unused after switching to SQLAlchemy 2.0.31. Alembic's Operations.bulk_insert is not working at the time of this note creation. Still, bulk_insert is considered the proper way to populate tables and should be used again when this issue is resolved. :param selector: Database name in settings.py module DB attribute :param url: SQLAlchemy Database URL :return: Alembic operations object \"\"\" if not url : url = Assistant . _provide_db_url ( selector ) engine = create_engine ( url ) context = MigrationContext . configure ( engine . connect ()) return Operations ( context ) @staticmethod def provide_context ( sessions : bool = True , _labels : Optional [ tuple [ dict ]] = None , _observers : Optional [ tuple [ str ]] = None , ) -> dict [ str , Union [ dict [ str , Union [ sessionmaker [ AsyncSession ], InfluxDBClient ]], str , list [ Union [ Type [ Adapter ], Type [ Observer ]]], ModuleType , ], ]: \"\"\" Creates Manager's constructor kwargs. :param sessions: Sessions option :param _labels: Optional tuple of Observer's names or class names :param _observers: Optional tuple of Observer's names or class names :return: Manager's constractor parameters :raises BasicManagerException: \"\"\" settings = Assistant . _provide_settings () context = { \"adapters\" : Assistant . _collect_classes ( \"adapters\" ), \"name\" : settings . NAME , \"observers\" : Assistant . _collect_classes ( \"observers\" ), \"path\" : os . getcwd (), \"settings\" : settings , } if sessions : context [ \"sessions\" ] = Assistant . _provide_sessions () if _labels : required_labels = { k : v for d in _labels for k , v in d . items ()} context [ \"observers\" ] = list ( filter ( lambda x : all ( x . LABELS . get ( k ) == v for k , v in required_labels . items () ), context [ \"observers\" ], ) ) if _observers : context [ \"observers\" ] = list ( filter ( lambda x : x . NAME in _observers # type: ignore or x . __name__ in _observers , context [ \"observers\" ], ) ) if not context [ \"observers\" ]: raise BasicManagerException ( \"No observers found or left after filtering\" ) return context @staticmethod def provide_models () -> list [ object ]: \"\"\" Gathers project models. :return: Models list \"\"\" settings = Assistant . _provide_settings () return [ locate ( i ) for i in settings . MODELS ] @staticmethod def _collect_classes ( directory : str , ) -> list [ Union [ Type [ Adapter ], Type [ Observer ]]]: \"\"\" Recursively collects all classes from a given directory matching its prefix (Adapter/Observer). :param directory: Either \"adapters\" or \"observers\" :return: List of matching class types \"\"\" classes = [] prefix = directory . capitalize ()[: - 1 ] base_dir = os . path . join ( os . getcwd (), directory ) for dirpath , _ , filenames in os . walk ( base_dir ): for filename in filenames : if not filename . endswith ( \".py\" ) or filename . startswith ( \"__init__\" ): continue full_path = os . path . join ( dirpath , filename ) rel_path = os . path . relpath ( full_path , os . getcwd ()) module_name = rel_path . replace ( os . sep , \".\" )[: - 3 ] spec = importlib . util . spec_from_file_location ( module_name , full_path ) if not spec or not spec . loader : continue module = importlib . util . module_from_spec ( spec ) sys . modules [ module_name ] = module spec . loader . exec_module ( module ) for name , cls in inspect . getmembers ( module , inspect . isclass ): if cls . __module__ != module_name : continue if name . startswith ( prefix ) and len ( name ) > len ( prefix ): classes . append ( cls ) return classes @staticmethod def _provide_db_url ( selector : str , _async : bool = False ) -> str : \"\"\" Creates database URL. :param selector: Database name in settings.py module DB attribute :param _async: Async URL flag :return: Database URL string :raises BasicManagerException: \"\"\" settings = Assistant . _provide_settings () try : db = settings . DB [ selector ] except KeyError : raise BasicManagerException ( f \"Database { selector } is not defined in settings.py\" ) if not db . get ( \"name\" ): db [ \"name\" ] = settings . NAME if _async : async_drivers = { \"mysql\" : \"asyncmy\" , \"postgresql\" : \"asyncpg\" , } driver = async_drivers [ db [ \"type\" ]] return \" {type} + {driver} :// {user} : {pass} @ {host} / {name} \" . format ( driver = driver , ** db ) return \" {type} :// {user} : {pass} @ {host} / {name} \" . format ( ** db ) @staticmethod def _provide_sessions () -> ( dict [ str , Union [ sessionmaker [ AsyncSession ], InfluxDBClient ]] ): \"\"\" Creates a dictionary of database sessions. :return: Database sessions dictionary \"\"\" _sessions : dict = {} settings = Assistant . _provide_settings () logger . opt ( colors = True ) . info ( f \"Number of expected db connections: \" f \"<yellow> { len ( settings . DB ) } </yellow>\" ) for db in settings . DB : _type = settings . DB [ db ][ \"type\" ] if _type in SUPPORTED_NOSQL_DATABASES : session = Assistant . __provide_nosql_sessions ( db , settings ) _sessions . update ({ db : session }) elif _type in SUPPORTED_SQL_DATABASES : session = Assistant . __provide_sql_sessions ( db , settings ) _sessions . update ({ db : session }) else : logger . warning ( f \"Database type { _type } is not supported\" ) return _sessions @staticmethod def _provide_settings () -> ModuleType : \"\"\" Imports project's settings.py module and returns it. :return: Project's settings.py module :raises BasicManagerException: \"\"\" try : import settings # type: ignore return settings except ImportError : raise BasicManagerException ( \"Framework did not found settings.py in the current directory\" ) @staticmethod def __log_database_connection ( db : str , settings : ModuleType ) -> None : \"\"\" Log database connection. :param db: database name from settings.py module :param settings: settings.py module :return: None \"\"\" host = settings . DB [ db ][ \"host\" ] port = settings . DB [ db ][ \"port\" ] logger . opt ( colors = True ) . info ( f \"Adding session with <yellow> { db } </yellow> at \" f \"<magenta> { host } : { port } </magenta> to context\" ) @staticmethod def __provide_nosql_sessions ( db : str , settings : ModuleType ) -> InfluxDBClient : \"\"\" Provides NoSQL database session. :param db: database name from settings.py module :param settings: settings.py module :return: InfluxDBClient object \"\"\" Assistant . __log_database_connection ( db , settings ) if settings . DB [ db ][ \"type\" ] == \"influxdb\" : return InfluxDBClient ( host = settings . DB [ db ][ \"host\" ], port = settings . DB [ db ][ \"port\" ], db = settings . DB [ db ] . get ( \"name\" , settings . NAME ), username = settings . DB [ db ][ \"user\" ], password = settings . DB [ db ][ \"pass\" ], ) return None @staticmethod def __provide_sql_sessions ( db : str , settings : ModuleType ) -> sessionmaker [ AsyncSession ]: \"\"\" Provides SQL database session. :param db: database name from settings.py module :param settings: settings.py module :return: AsyncSession created with session maker \"\"\" Assistant . __log_database_connection ( db , settings ) return sessionmaker ( create_async_engine ( Assistant . _provide_db_url ( db , _async = True )), class_ = AsyncSession , expire_on_commit = False , ) provide_alembic_config ( path : str , selector : str , url : Optional [ str ] = None ) -> Config staticmethod Creates Alembic's configuration object. :param path: Migration directory path :param selector: Database name in settings.py module DB attribute :param url: SQLAlchemy Database URL :return: Alembic configuration object Source code in illuminate/manager/assistant.py @staticmethod def provide_alembic_config ( path : str , selector : str , url : Optional [ str ] = None ) -> Config : \"\"\" Creates Alembic's configuration object. :param path: Migration directory path :param selector: Database name in settings.py module DB attribute :param url: SQLAlchemy Database URL :return: Alembic configuration object \"\"\" if not url : url = Assistant . _provide_db_url ( selector ) config = Config () config . set_main_option ( \"script_location\" , os . path . join ( path , \"migrations\" ) ) config . set_main_option ( \"sqlalchemy.url\" , url ) return config provide_alembic_operations ( selector : str , url : Optional [ str ] = None ) -> Operations staticmethod Creates Alembic's operations object. NOTE: Currently unused after switching to SQLAlchemy 2.0.31. Alembic's Operations.bulk_insert is not working at the time of this note creation. Still, bulk_insert is considered the proper way to populate tables and should be used again when this issue is resolved. :param selector: Database name in settings.py module DB attribute :param url: SQLAlchemy Database URL :return: Alembic operations object Source code in illuminate/manager/assistant.py @staticmethod def provide_alembic_operations ( selector : str , url : Optional [ str ] = None ) -> Operations : \"\"\" Creates Alembic's operations object. NOTE: Currently unused after switching to SQLAlchemy 2.0.31. Alembic's Operations.bulk_insert is not working at the time of this note creation. Still, bulk_insert is considered the proper way to populate tables and should be used again when this issue is resolved. :param selector: Database name in settings.py module DB attribute :param url: SQLAlchemy Database URL :return: Alembic operations object \"\"\" if not url : url = Assistant . _provide_db_url ( selector ) engine = create_engine ( url ) context = MigrationContext . configure ( engine . connect ()) return Operations ( context ) provide_context ( sessions : bool = True , _labels : Optional [ tuple [ dict ]] = None , _observers : Optional [ tuple [ str ]] = None ) -> dict [ str , Union [ dict [ str , Union [ sessionmaker [ AsyncSession ], InfluxDBClient ]], str , list [ Union [ Type [ Adapter ], Type [ Observer ]]], ModuleType ]] staticmethod Creates Manager's constructor kwargs. :param sessions: Sessions option :param _labels: Optional tuple of Observer's names or class names :param _observers: Optional tuple of Observer's names or class names :return: Manager's constractor parameters :raises BasicManagerException: Source code in illuminate/manager/assistant.py @staticmethod def provide_context ( sessions : bool = True , _labels : Optional [ tuple [ dict ]] = None , _observers : Optional [ tuple [ str ]] = None , ) -> dict [ str , Union [ dict [ str , Union [ sessionmaker [ AsyncSession ], InfluxDBClient ]], str , list [ Union [ Type [ Adapter ], Type [ Observer ]]], ModuleType , ], ]: \"\"\" Creates Manager's constructor kwargs. :param sessions: Sessions option :param _labels: Optional tuple of Observer's names or class names :param _observers: Optional tuple of Observer's names or class names :return: Manager's constractor parameters :raises BasicManagerException: \"\"\" settings = Assistant . _provide_settings () context = { \"adapters\" : Assistant . _collect_classes ( \"adapters\" ), \"name\" : settings . NAME , \"observers\" : Assistant . _collect_classes ( \"observers\" ), \"path\" : os . getcwd (), \"settings\" : settings , } if sessions : context [ \"sessions\" ] = Assistant . _provide_sessions () if _labels : required_labels = { k : v for d in _labels for k , v in d . items ()} context [ \"observers\" ] = list ( filter ( lambda x : all ( x . LABELS . get ( k ) == v for k , v in required_labels . items () ), context [ \"observers\" ], ) ) if _observers : context [ \"observers\" ] = list ( filter ( lambda x : x . NAME in _observers # type: ignore or x . __name__ in _observers , context [ \"observers\" ], ) ) if not context [ \"observers\" ]: raise BasicManagerException ( \"No observers found or left after filtering\" ) return context provide_models () -> list [ object ] staticmethod Gathers project models. :return: Models list Source code in illuminate/manager/assistant.py @staticmethod def provide_models () -> list [ object ]: \"\"\" Gathers project models. :return: Models list \"\"\" settings = Assistant . _provide_settings () return [ locate ( i ) for i in settings . MODELS ] illuminate.manager.manager.Manager ( IManager ) Manager class, executes framework's cli commands. All public methods correspond to cli commands. It should only be instantiated when 'illuminate observe start' command is used with kwargs provided by Assistant class. Source code in illuminate/manager/manager.py class Manager ( IManager ): \"\"\" Manager class, executes framework's cli commands. All public methods correspond to cli commands. It should only be instantiated when 'illuminate observe start' command is used with kwargs provided by Assistant class. \"\"\" def __init__ ( self , adapters : list [ Type [ Adapter ]], name : str , observers : list [ Type [ Observer ]], path : str , sessions : dict [ str , Union [ Type [ AsyncSession ], InfluxDBClient ]], settings : ModuleType , * args , ** kwargs , ): \"\"\" Manager's __init__ method. :param adapters: List of Adapters found in project files :param name: Project's name :param observers: List of Observers found in project files after filtering :param path: Path to project files :param sessions: Database sessions :param settings: Project's settings.py module \"\"\" self . adapters = adapters self . name = name self . observers = observers self . path = path self . sessions = sessions self . settings = settings self . _adapters : list [ Adapter ] = [] self . _observers : list [ Observer ] = [] self . __observe_queue : queues . Queue = queues . Queue () self . __adapt_queue : queues . Queue = queues . Queue () self . __export_queue : queues . Queue = queues . Queue () self . __exported : set = set () self . __not_observed : set = set () self . __observed : set = set () self . __observing : set = set () @property def exported ( self ) -> set : return self . __exported @property def not_observed ( self ) -> set : return self . __not_observed @property def observed ( self ) -> set : return self . __observed @staticmethod @adapt ( \"populate\" ) def db_populate ( fixtures : tuple [ str ], selector : str , url : str , ) -> None : \"\"\" Populates database with fixtures. :param fixtures: Tuple of fixture files :param selector: Database name in settings.py module :param url: SQLAlchemy Database URL :return: None \"\"\" models = Assistant . provide_models () table_data = {} for _file in fixtures : with open ( _file , \"r\" ) as file : # type: ignore content = json . load ( file ) # type: ignore for table in content : table_data . update ({ table [ \"name\" ]: table [ \"data\" ]}) with Session ( create_engine ( url )) as session : for model in models : if model . __tablename__ in table_data : # type: ignore data = table_data [ model . __tablename__ ] # type: ignore for record in data : session . add ( model ( ** record )) # type: ignore logger . debug ( f \"Row { record } added to \" # type: ignore f \"table buffer { model . __tablename__ } \" ) session . commit () logger . success ( f \"Database { selector } populated\" ) @staticmethod @adapt ( \"revision\" ) def db_revision ( config : Config , revision : str , ) -> None : \"\"\" Creates Alembic's revision file in migration directory. :param config: Alembic's configuration object :param revision: Parent revision :return: None \"\"\" command . revision ( config , autogenerate = True , head = revision , ) logger . success ( \"Revision created\" ) @staticmethod @adapt ( \"upgrade\" ) def db_upgrade ( config : Config , revision : str , selector : str , ) -> None : \"\"\" Applies migration file to a database. :param config: Alembic's configuration object :param revision: Revision to apply to database :param selector: Database name in settings.py module :return: None \"\"\" command . upgrade ( config , revision ) logger . success ( f \"Database { selector } upgraded\" ) @staticmethod def project_setup ( name : str , path : str ) -> None : \"\"\" Creates a project directory with all needed files. :param name: Project's name :param path: Path to project files :return: None :raises BasicManagerException: \"\"\" if path != \".\" : path = os . path . join ( path , name ) if os . path . exists ( path ): raise BasicManagerException ( \"Directory already exists\" ) logger . opt ( colors = True ) . info ( f \"Creating project directory for project \" f \"<yellow> { name } </yellow>\" ) os . mkdir ( path ) for _name , content in FILES . items (): file_path = os . path . join ( path , _name ) if os . sep in _name : os . makedirs ( os . sep . join ( file_path . split ( os . sep )[: - 1 ]), exist_ok = True ) with open ( file_path , \"w\" ) as file : logger . debug ( f \"Creating project file { _name } at { file_path } \" ) file . write ( f \" { content . format ( name = name ) . strip () } \\n \" ) logger . success ( f \"Project structure created for { name } \" ) @staticmethod @show_observer_catalogue def observe_catalogue ( ** context ) -> dict : \"\"\" Pass context dict to illuminate.decorators.cli.show_observe_catalogue. :return: dict \"\"\" return context @show_logo @show_info def observe_start ( self ) -> None : \"\"\" Starts producer/consumer ETL process. :return: None \"\"\" io_loop = ioloop . IOLoop . current () io_loop . run_sync ( self . _observe_start ) async def __start ( self ) -> None : \"\"\" Initializes Adapters and Observers and pass initial Observation objects to self.__observation. :return: None \"\"\" for adapter in self . adapters : self . _adapters . append ( adapter ( manager = self )) logger . opt ( colors = True ) . info ( f \"Adapter <yellow> { adapter . __name__ } </yellow> initialized\" ) for observer in self . observers : instance = observer ( manager = self ) self . _observers . append ( instance ) logger . opt ( colors = True ) . info ( f \"Observer <yellow> { observer . __name__ } </yellow> initialized\" ) for _observation in instance . initial_observations : await self . __router ( _observation ) async def __router ( self , item : Union [ Exporter , Finding , Observation ] ) -> None : \"\"\" Routes object based on its class to proper queue. :param item: Exporter, Finding or Observation object :return: None \"\"\" if isinstance ( item , Exporter ): await self . __export_queue . put ( item ) elif isinstance ( item , Finding ): if inspect . stack ()[ 1 ][ 3 ] != \"__adaptation\" : await self . __adapt_queue . put ( item ) else : logger . warning ( f \"Findings can only yield Exporters and Observations \" f \"thus rejecting item { item } \" ) elif isinstance ( item , Observation ): _hash = hash ( item ) if _hash not in self . __observing : self . __observing . add ( _hash ) if isinstance ( item , HTTPObservation ) and not item . allowed : return await self . __observe_queue . put ( item ) else : logger . warning ( f \"Manager rejected item { item } due to unsupported \" f \"item type { type ( item ) } \" ) @logger . catch async def __observe ( self ) -> None : \"\"\" Takes Observation object from self.__observe_queue and, after delay, pass it to self.__observation method. :return: None \"\"\" async for item in self . __observe_queue : if not item : return await asyncio . sleep ( self . settings . OBSERVATION_CONFIGURATION [ \"delay\" ] ) await self . __observation_switch ( item ) logger . debug ( f \"Coroutine observed { item } \" ) del item self . __observe_queue . task_done () async def __observe_file ( self , item : FileObservation ) -> None : \"\"\" Calls FileObservation's observe method and pass result to resolve function. :param item: FileObservation object :return: None \"\"\" async with item . observe ( xcom = item . xcom ) as result : await self . __observation_resolve ( result , item . url ) async def __observe_http ( self , item : HTTPObservation ) -> None : \"\"\" Prepares HTTPObservation configuration, calls observe method and pass result to resolve function. :param item: HTTPObservation object :return: None \"\"\" item . configuration = { ** self . settings . OBSERVATION_CONFIGURATION [ \"http\" ], ** item . configuration , } result = await item . observe ( xcom = item . xcom ) await self . __observation_resolve ( result , item . url ) async def __observe_sql ( self , item : SQLObservation ) -> None : \"\"\" Calls SQLObservation's observe method and pass result to resolve function. :param item: SQLObservation object :return: None \"\"\" result = await item . observe ( self . sessions [ item . url ], xcom = item . xcom ) await self . __observation_resolve ( result , f \" { item . url } : { item . query } \" ) async def __observe_splash ( self , item : SplashObservation ) -> None : \"\"\" Prepares SplashObservation configuration, calls observe method and pass result to resolve function. :param item: SplashObservation object :return: None \"\"\" item . configuration = { ** self . settings . OBSERVATION_CONFIGURATION [ \"splash\" ], ** item . configuration , } result = await item . observe ( self . settings . OBSERVATION_CONFIGURATION [ \"http\" ], xcom = item . xcom ) await self . __observation_resolve ( result , item . url ) async def __observation_resolve ( self , result : Union [ None , Result ], url : str ): \"\"\" Resolves Observation. :param result: Result :param url: URL str :return: None \"\"\" if not result : self . __not_observed . add ( url ) return self . __observed . add ( url ) try : if inspect . isawaitable ( result ): await result if inspect . isasyncgen ( result ): async for _item in result : await self . __router ( _item ) except Exception : # noqa stack = traceback . format_exc () . strip () . replace ( \"<\" , \" \\\\ <\" ) logger . opt ( colors = True ) . warning ( \"Observation callback throws the following exception \\n \" f \"<red> { stack } </red>\" ) async def __observation_switch ( self , item : Observation ) -> None : \"\"\" Passes Observation object to proper method based on its class. :param item: Observation object :return: None \"\"\" if isinstance ( item , HTTPObservation ): if isinstance ( item , SplashObservation ): await self . __observe_splash ( item ) else : await self . __observe_http ( item ) elif isinstance ( item , FileObservation ): await self . __observe_file ( item ) elif isinstance ( item , SQLObservation ): await self . __observe_sql ( item ) else : logger . warning ( f \"Observation of a type { type ( item ) } is not supported\" ) @logger . catch async def __adapt ( self ) -> None : \"\"\" Takes Finding object from self.__adapt_queue and pass it to self.__adaptation method. :return: None \"\"\" async for item in self . __adapt_queue : if not item : return await self . __adaptation ( item ) logger . debug ( f \"Coroutine adapted { item } \" ) del item self . __adapt_queue . task_done () async def __adaptation ( self , item : Finding ) -> None : \"\"\" Passes Finding object to Adapter's instance adapt method. :param item: Finding object :return: None \"\"\" for adapter in self . _adapters : for subscriber in adapter . subscribers : if isinstance ( item , subscriber ): try : items = adapter . adapt ( item ) async for _item in items : # type: ignore await self . __router ( _item ) except Exception as exception : logger . warning ( f \" { self } .adapt() -> { exception } \" ) @logger . catch async def __export ( self ) -> None : \"\"\" Takes Exporter object from self.__export_queue and pass it to self.__exportation method. :return: None \"\"\" async for item in self . __export_queue : if not item : return await self . __export_to ( item ) logger . debug ( f \"Coroutine exported { item } \" ) del item self . __export_queue . task_done () async def __export_to ( self , item : Exporter ) -> None : \"\"\" Passes Exporter object to proper method based on its class. :param item: Exporter object :return: None \"\"\" if isinstance ( item , ( InfluxDBExporter , SQLExporter )): await self . __export_to_database ( item ) async def __export_to_database ( self , item : Union [ InfluxDBExporter , SQLExporter ] ) -> None : \"\"\" Acquires database session based on Exporter's attributes and pass it to Exporter's export method. :param item: InfluxDBExporter or SQLExporter object :return: None \"\"\" try : session = self . sessions [ item . name ] await item . export ( session ) self . __exported . add ( item ) except BasicExporterException : pass except KeyError : logger . warning ( f \"Database { item . name } of is not found in context\" ) @logger . catch async def _observe_start ( self ) -> None : \"\"\" Starts producer/consumer ETL process. :return: None \"\"\" self . adapters . sort ( key = lambda x : x . priority , reverse = True ) _adapters = self . settings . CONCURRENCY [ \"adapters\" ] _exporters = self . settings . CONCURRENCY [ \"exporters\" ] _obs = self . settings . CONCURRENCY [ \"observations\" ] adapters = gen . multi ([ self . __adapt () for _ in range ( _adapters )]) exporters = gen . multi ([ self . __export () for _ in range ( _exporters )]) observations = gen . multi ([ self . __observe () for _ in range ( _obs )]) await self . __start () await self . __observe_queue . join () await self . __adapt_queue . join () await self . __export_queue . join () for _ in range ( _obs ): await self . __observe_queue . put ( None ) for _ in range ( _adapters ): await self . __adapt_queue . put ( None ) for _ in range ( _exporters ): await self . __export_queue . put ( None ) await adapters await exporters await observations for session in self . sessions : if isinstance ( self . sessions [ session ], InfluxDBClient ): await self . sessions [ session ] . close () # type: ignore __init__ ( self , adapters : list [ Type [ Adapter ]], name : str , observers : list [ Type [ Observer ]], path : str , sessions : dict [ str , Union [ Type [ AsyncSession ], InfluxDBClient ]], settings : ModuleType , * args , ** kwargs ) special Manager's init method. :param adapters: List of Adapters found in project files :param name: Project's name :param observers: List of Observers found in project files after filtering :param path: Path to project files :param sessions: Database sessions :param settings: Project's settings.py module Source code in illuminate/manager/manager.py def __init__ ( self , adapters : list [ Type [ Adapter ]], name : str , observers : list [ Type [ Observer ]], path : str , sessions : dict [ str , Union [ Type [ AsyncSession ], InfluxDBClient ]], settings : ModuleType , * args , ** kwargs , ): \"\"\" Manager's __init__ method. :param adapters: List of Adapters found in project files :param name: Project's name :param observers: List of Observers found in project files after filtering :param path: Path to project files :param sessions: Database sessions :param settings: Project's settings.py module \"\"\" self . adapters = adapters self . name = name self . observers = observers self . path = path self . sessions = sessions self . settings = settings self . _adapters : list [ Adapter ] = [] self . _observers : list [ Observer ] = [] self . __observe_queue : queues . Queue = queues . Queue () self . __adapt_queue : queues . Queue = queues . Queue () self . __export_queue : queues . Queue = queues . Queue () self . __exported : set = set () self . __not_observed : set = set () self . __observed : set = set () self . __observing : set = set () db_populate ( fixtures : tuple [ str ], selector : str , url : str ) -> None staticmethod Populates database with fixtures. :param fixtures: Tuple of fixture files :param selector: Database name in settings.py module :param url: SQLAlchemy Database URL :return: None Source code in illuminate/manager/manager.py @staticmethod @adapt ( \"populate\" ) def db_populate ( fixtures : tuple [ str ], selector : str , url : str , ) -> None : \"\"\" Populates database with fixtures. :param fixtures: Tuple of fixture files :param selector: Database name in settings.py module :param url: SQLAlchemy Database URL :return: None \"\"\" models = Assistant . provide_models () table_data = {} for _file in fixtures : with open ( _file , \"r\" ) as file : # type: ignore content = json . load ( file ) # type: ignore for table in content : table_data . update ({ table [ \"name\" ]: table [ \"data\" ]}) with Session ( create_engine ( url )) as session : for model in models : if model . __tablename__ in table_data : # type: ignore data = table_data [ model . __tablename__ ] # type: ignore for record in data : session . add ( model ( ** record )) # type: ignore logger . debug ( f \"Row { record } added to \" # type: ignore f \"table buffer { model . __tablename__ } \" ) session . commit () logger . success ( f \"Database { selector } populated\" ) db_revision ( config : Config , revision : str ) -> None staticmethod Creates Alembic's revision file in migration directory. :param config: Alembic's configuration object :param revision: Parent revision :return: None Source code in illuminate/manager/manager.py @staticmethod @adapt ( \"revision\" ) def db_revision ( config : Config , revision : str , ) -> None : \"\"\" Creates Alembic's revision file in migration directory. :param config: Alembic's configuration object :param revision: Parent revision :return: None \"\"\" command . revision ( config , autogenerate = True , head = revision , ) logger . success ( \"Revision created\" ) db_upgrade ( config : Config , revision : str , selector : str ) -> None staticmethod Applies migration file to a database. :param config: Alembic's configuration object :param revision: Revision to apply to database :param selector: Database name in settings.py module :return: None Source code in illuminate/manager/manager.py @staticmethod @adapt ( \"upgrade\" ) def db_upgrade ( config : Config , revision : str , selector : str , ) -> None : \"\"\" Applies migration file to a database. :param config: Alembic's configuration object :param revision: Revision to apply to database :param selector: Database name in settings.py module :return: None \"\"\" command . upgrade ( config , revision ) logger . success ( f \"Database { selector } upgraded\" ) observe_catalogue ( ** context ) -> dict staticmethod Pass context dict to illuminate.decorators.cli.show_observe_catalogue. :return: dict Source code in illuminate/manager/manager.py @staticmethod @show_observer_catalogue def observe_catalogue ( ** context ) -> dict : \"\"\" Pass context dict to illuminate.decorators.cli.show_observe_catalogue. :return: dict \"\"\" return context observe_start ( self ) -> None Starts producer/consumer ETL process. :return: None Source code in illuminate/manager/manager.py @show_logo @show_info def observe_start ( self ) -> None : \"\"\" Starts producer/consumer ETL process. :return: None \"\"\" io_loop = ioloop . IOLoop . current () io_loop . run_sync ( self . _observe_start ) project_setup ( name : str , path : str ) -> None staticmethod Creates a project directory with all needed files. :param name: Project's name :param path: Path to project files :return: None :raises BasicManagerException: Source code in illuminate/manager/manager.py @staticmethod def project_setup ( name : str , path : str ) -> None : \"\"\" Creates a project directory with all needed files. :param name: Project's name :param path: Path to project files :return: None :raises BasicManagerException: \"\"\" if path != \".\" : path = os . path . join ( path , name ) if os . path . exists ( path ): raise BasicManagerException ( \"Directory already exists\" ) logger . opt ( colors = True ) . info ( f \"Creating project directory for project \" f \"<yellow> { name } </yellow>\" ) os . mkdir ( path ) for _name , content in FILES . items (): file_path = os . path . join ( path , _name ) if os . sep in _name : os . makedirs ( os . sep . join ( file_path . split ( os . sep )[: - 1 ]), exist_ok = True ) with open ( file_path , \"w\" ) as file : logger . debug ( f \"Creating project file { _name } at { file_path } \" ) file . write ( f \" { content . format ( name = name ) . strip () } \\n \" ) logger . success ( f \"Project structure created for { name } \" )","title":"Core Classes"},{"location":"core/#illuminate.manager.assistant.Assistant","text":"Assistant class, creates objects from project files. Used by Manager class in its static methods and cli start function to initialize Manager. Source code in illuminate/manager/assistant.py class Assistant ( IAssistant ): \"\"\" Assistant class, creates objects from project files. Used by Manager class in its static methods and cli start function to initialize Manager. \"\"\" @staticmethod def provide_alembic_config ( path : str , selector : str , url : Optional [ str ] = None ) -> Config : \"\"\" Creates Alembic's configuration object. :param path: Migration directory path :param selector: Database name in settings.py module DB attribute :param url: SQLAlchemy Database URL :return: Alembic configuration object \"\"\" if not url : url = Assistant . _provide_db_url ( selector ) config = Config () config . set_main_option ( \"script_location\" , os . path . join ( path , \"migrations\" ) ) config . set_main_option ( \"sqlalchemy.url\" , url ) return config @staticmethod def provide_alembic_operations ( selector : str , url : Optional [ str ] = None ) -> Operations : \"\"\" Creates Alembic's operations object. NOTE: Currently unused after switching to SQLAlchemy 2.0.31. Alembic's Operations.bulk_insert is not working at the time of this note creation. Still, bulk_insert is considered the proper way to populate tables and should be used again when this issue is resolved. :param selector: Database name in settings.py module DB attribute :param url: SQLAlchemy Database URL :return: Alembic operations object \"\"\" if not url : url = Assistant . _provide_db_url ( selector ) engine = create_engine ( url ) context = MigrationContext . configure ( engine . connect ()) return Operations ( context ) @staticmethod def provide_context ( sessions : bool = True , _labels : Optional [ tuple [ dict ]] = None , _observers : Optional [ tuple [ str ]] = None , ) -> dict [ str , Union [ dict [ str , Union [ sessionmaker [ AsyncSession ], InfluxDBClient ]], str , list [ Union [ Type [ Adapter ], Type [ Observer ]]], ModuleType , ], ]: \"\"\" Creates Manager's constructor kwargs. :param sessions: Sessions option :param _labels: Optional tuple of Observer's names or class names :param _observers: Optional tuple of Observer's names or class names :return: Manager's constractor parameters :raises BasicManagerException: \"\"\" settings = Assistant . _provide_settings () context = { \"adapters\" : Assistant . _collect_classes ( \"adapters\" ), \"name\" : settings . NAME , \"observers\" : Assistant . _collect_classes ( \"observers\" ), \"path\" : os . getcwd (), \"settings\" : settings , } if sessions : context [ \"sessions\" ] = Assistant . _provide_sessions () if _labels : required_labels = { k : v for d in _labels for k , v in d . items ()} context [ \"observers\" ] = list ( filter ( lambda x : all ( x . LABELS . get ( k ) == v for k , v in required_labels . items () ), context [ \"observers\" ], ) ) if _observers : context [ \"observers\" ] = list ( filter ( lambda x : x . NAME in _observers # type: ignore or x . __name__ in _observers , context [ \"observers\" ], ) ) if not context [ \"observers\" ]: raise BasicManagerException ( \"No observers found or left after filtering\" ) return context @staticmethod def provide_models () -> list [ object ]: \"\"\" Gathers project models. :return: Models list \"\"\" settings = Assistant . _provide_settings () return [ locate ( i ) for i in settings . MODELS ] @staticmethod def _collect_classes ( directory : str , ) -> list [ Union [ Type [ Adapter ], Type [ Observer ]]]: \"\"\" Recursively collects all classes from a given directory matching its prefix (Adapter/Observer). :param directory: Either \"adapters\" or \"observers\" :return: List of matching class types \"\"\" classes = [] prefix = directory . capitalize ()[: - 1 ] base_dir = os . path . join ( os . getcwd (), directory ) for dirpath , _ , filenames in os . walk ( base_dir ): for filename in filenames : if not filename . endswith ( \".py\" ) or filename . startswith ( \"__init__\" ): continue full_path = os . path . join ( dirpath , filename ) rel_path = os . path . relpath ( full_path , os . getcwd ()) module_name = rel_path . replace ( os . sep , \".\" )[: - 3 ] spec = importlib . util . spec_from_file_location ( module_name , full_path ) if not spec or not spec . loader : continue module = importlib . util . module_from_spec ( spec ) sys . modules [ module_name ] = module spec . loader . exec_module ( module ) for name , cls in inspect . getmembers ( module , inspect . isclass ): if cls . __module__ != module_name : continue if name . startswith ( prefix ) and len ( name ) > len ( prefix ): classes . append ( cls ) return classes @staticmethod def _provide_db_url ( selector : str , _async : bool = False ) -> str : \"\"\" Creates database URL. :param selector: Database name in settings.py module DB attribute :param _async: Async URL flag :return: Database URL string :raises BasicManagerException: \"\"\" settings = Assistant . _provide_settings () try : db = settings . DB [ selector ] except KeyError : raise BasicManagerException ( f \"Database { selector } is not defined in settings.py\" ) if not db . get ( \"name\" ): db [ \"name\" ] = settings . NAME if _async : async_drivers = { \"mysql\" : \"asyncmy\" , \"postgresql\" : \"asyncpg\" , } driver = async_drivers [ db [ \"type\" ]] return \" {type} + {driver} :// {user} : {pass} @ {host} / {name} \" . format ( driver = driver , ** db ) return \" {type} :// {user} : {pass} @ {host} / {name} \" . format ( ** db ) @staticmethod def _provide_sessions () -> ( dict [ str , Union [ sessionmaker [ AsyncSession ], InfluxDBClient ]] ): \"\"\" Creates a dictionary of database sessions. :return: Database sessions dictionary \"\"\" _sessions : dict = {} settings = Assistant . _provide_settings () logger . opt ( colors = True ) . info ( f \"Number of expected db connections: \" f \"<yellow> { len ( settings . DB ) } </yellow>\" ) for db in settings . DB : _type = settings . DB [ db ][ \"type\" ] if _type in SUPPORTED_NOSQL_DATABASES : session = Assistant . __provide_nosql_sessions ( db , settings ) _sessions . update ({ db : session }) elif _type in SUPPORTED_SQL_DATABASES : session = Assistant . __provide_sql_sessions ( db , settings ) _sessions . update ({ db : session }) else : logger . warning ( f \"Database type { _type } is not supported\" ) return _sessions @staticmethod def _provide_settings () -> ModuleType : \"\"\" Imports project's settings.py module and returns it. :return: Project's settings.py module :raises BasicManagerException: \"\"\" try : import settings # type: ignore return settings except ImportError : raise BasicManagerException ( \"Framework did not found settings.py in the current directory\" ) @staticmethod def __log_database_connection ( db : str , settings : ModuleType ) -> None : \"\"\" Log database connection. :param db: database name from settings.py module :param settings: settings.py module :return: None \"\"\" host = settings . DB [ db ][ \"host\" ] port = settings . DB [ db ][ \"port\" ] logger . opt ( colors = True ) . info ( f \"Adding session with <yellow> { db } </yellow> at \" f \"<magenta> { host } : { port } </magenta> to context\" ) @staticmethod def __provide_nosql_sessions ( db : str , settings : ModuleType ) -> InfluxDBClient : \"\"\" Provides NoSQL database session. :param db: database name from settings.py module :param settings: settings.py module :return: InfluxDBClient object \"\"\" Assistant . __log_database_connection ( db , settings ) if settings . DB [ db ][ \"type\" ] == \"influxdb\" : return InfluxDBClient ( host = settings . DB [ db ][ \"host\" ], port = settings . DB [ db ][ \"port\" ], db = settings . DB [ db ] . get ( \"name\" , settings . NAME ), username = settings . DB [ db ][ \"user\" ], password = settings . DB [ db ][ \"pass\" ], ) return None @staticmethod def __provide_sql_sessions ( db : str , settings : ModuleType ) -> sessionmaker [ AsyncSession ]: \"\"\" Provides SQL database session. :param db: database name from settings.py module :param settings: settings.py module :return: AsyncSession created with session maker \"\"\" Assistant . __log_database_connection ( db , settings ) return sessionmaker ( create_async_engine ( Assistant . _provide_db_url ( db , _async = True )), class_ = AsyncSession , expire_on_commit = False , )","title":"Assistant"},{"location":"core/#illuminate.manager.assistant.Assistant.provide_alembic_config","text":"Creates Alembic's configuration object. :param path: Migration directory path :param selector: Database name in settings.py module DB attribute :param url: SQLAlchemy Database URL :return: Alembic configuration object Source code in illuminate/manager/assistant.py @staticmethod def provide_alembic_config ( path : str , selector : str , url : Optional [ str ] = None ) -> Config : \"\"\" Creates Alembic's configuration object. :param path: Migration directory path :param selector: Database name in settings.py module DB attribute :param url: SQLAlchemy Database URL :return: Alembic configuration object \"\"\" if not url : url = Assistant . _provide_db_url ( selector ) config = Config () config . set_main_option ( \"script_location\" , os . path . join ( path , \"migrations\" ) ) config . set_main_option ( \"sqlalchemy.url\" , url ) return config","title":"provide_alembic_config()"},{"location":"core/#illuminate.manager.assistant.Assistant.provide_alembic_operations","text":"Creates Alembic's operations object. NOTE: Currently unused after switching to SQLAlchemy 2.0.31. Alembic's Operations.bulk_insert is not working at the time of this note creation. Still, bulk_insert is considered the proper way to populate tables and should be used again when this issue is resolved. :param selector: Database name in settings.py module DB attribute :param url: SQLAlchemy Database URL :return: Alembic operations object Source code in illuminate/manager/assistant.py @staticmethod def provide_alembic_operations ( selector : str , url : Optional [ str ] = None ) -> Operations : \"\"\" Creates Alembic's operations object. NOTE: Currently unused after switching to SQLAlchemy 2.0.31. Alembic's Operations.bulk_insert is not working at the time of this note creation. Still, bulk_insert is considered the proper way to populate tables and should be used again when this issue is resolved. :param selector: Database name in settings.py module DB attribute :param url: SQLAlchemy Database URL :return: Alembic operations object \"\"\" if not url : url = Assistant . _provide_db_url ( selector ) engine = create_engine ( url ) context = MigrationContext . configure ( engine . connect ()) return Operations ( context )","title":"provide_alembic_operations()"},{"location":"core/#illuminate.manager.assistant.Assistant.provide_context","text":"Creates Manager's constructor kwargs. :param sessions: Sessions option :param _labels: Optional tuple of Observer's names or class names :param _observers: Optional tuple of Observer's names or class names :return: Manager's constractor parameters :raises BasicManagerException: Source code in illuminate/manager/assistant.py @staticmethod def provide_context ( sessions : bool = True , _labels : Optional [ tuple [ dict ]] = None , _observers : Optional [ tuple [ str ]] = None , ) -> dict [ str , Union [ dict [ str , Union [ sessionmaker [ AsyncSession ], InfluxDBClient ]], str , list [ Union [ Type [ Adapter ], Type [ Observer ]]], ModuleType , ], ]: \"\"\" Creates Manager's constructor kwargs. :param sessions: Sessions option :param _labels: Optional tuple of Observer's names or class names :param _observers: Optional tuple of Observer's names or class names :return: Manager's constractor parameters :raises BasicManagerException: \"\"\" settings = Assistant . _provide_settings () context = { \"adapters\" : Assistant . _collect_classes ( \"adapters\" ), \"name\" : settings . NAME , \"observers\" : Assistant . _collect_classes ( \"observers\" ), \"path\" : os . getcwd (), \"settings\" : settings , } if sessions : context [ \"sessions\" ] = Assistant . _provide_sessions () if _labels : required_labels = { k : v for d in _labels for k , v in d . items ()} context [ \"observers\" ] = list ( filter ( lambda x : all ( x . LABELS . get ( k ) == v for k , v in required_labels . items () ), context [ \"observers\" ], ) ) if _observers : context [ \"observers\" ] = list ( filter ( lambda x : x . NAME in _observers # type: ignore or x . __name__ in _observers , context [ \"observers\" ], ) ) if not context [ \"observers\" ]: raise BasicManagerException ( \"No observers found or left after filtering\" ) return context","title":"provide_context()"},{"location":"core/#illuminate.manager.assistant.Assistant.provide_models","text":"Gathers project models. :return: Models list Source code in illuminate/manager/assistant.py @staticmethod def provide_models () -> list [ object ]: \"\"\" Gathers project models. :return: Models list \"\"\" settings = Assistant . _provide_settings () return [ locate ( i ) for i in settings . MODELS ]","title":"provide_models()"},{"location":"core/#illuminate.manager.manager.Manager","text":"Manager class, executes framework's cli commands. All public methods correspond to cli commands. It should only be instantiated when 'illuminate observe start' command is used with kwargs provided by Assistant class. Source code in illuminate/manager/manager.py class Manager ( IManager ): \"\"\" Manager class, executes framework's cli commands. All public methods correspond to cli commands. It should only be instantiated when 'illuminate observe start' command is used with kwargs provided by Assistant class. \"\"\" def __init__ ( self , adapters : list [ Type [ Adapter ]], name : str , observers : list [ Type [ Observer ]], path : str , sessions : dict [ str , Union [ Type [ AsyncSession ], InfluxDBClient ]], settings : ModuleType , * args , ** kwargs , ): \"\"\" Manager's __init__ method. :param adapters: List of Adapters found in project files :param name: Project's name :param observers: List of Observers found in project files after filtering :param path: Path to project files :param sessions: Database sessions :param settings: Project's settings.py module \"\"\" self . adapters = adapters self . name = name self . observers = observers self . path = path self . sessions = sessions self . settings = settings self . _adapters : list [ Adapter ] = [] self . _observers : list [ Observer ] = [] self . __observe_queue : queues . Queue = queues . Queue () self . __adapt_queue : queues . Queue = queues . Queue () self . __export_queue : queues . Queue = queues . Queue () self . __exported : set = set () self . __not_observed : set = set () self . __observed : set = set () self . __observing : set = set () @property def exported ( self ) -> set : return self . __exported @property def not_observed ( self ) -> set : return self . __not_observed @property def observed ( self ) -> set : return self . __observed @staticmethod @adapt ( \"populate\" ) def db_populate ( fixtures : tuple [ str ], selector : str , url : str , ) -> None : \"\"\" Populates database with fixtures. :param fixtures: Tuple of fixture files :param selector: Database name in settings.py module :param url: SQLAlchemy Database URL :return: None \"\"\" models = Assistant . provide_models () table_data = {} for _file in fixtures : with open ( _file , \"r\" ) as file : # type: ignore content = json . load ( file ) # type: ignore for table in content : table_data . update ({ table [ \"name\" ]: table [ \"data\" ]}) with Session ( create_engine ( url )) as session : for model in models : if model . __tablename__ in table_data : # type: ignore data = table_data [ model . __tablename__ ] # type: ignore for record in data : session . add ( model ( ** record )) # type: ignore logger . debug ( f \"Row { record } added to \" # type: ignore f \"table buffer { model . __tablename__ } \" ) session . commit () logger . success ( f \"Database { selector } populated\" ) @staticmethod @adapt ( \"revision\" ) def db_revision ( config : Config , revision : str , ) -> None : \"\"\" Creates Alembic's revision file in migration directory. :param config: Alembic's configuration object :param revision: Parent revision :return: None \"\"\" command . revision ( config , autogenerate = True , head = revision , ) logger . success ( \"Revision created\" ) @staticmethod @adapt ( \"upgrade\" ) def db_upgrade ( config : Config , revision : str , selector : str , ) -> None : \"\"\" Applies migration file to a database. :param config: Alembic's configuration object :param revision: Revision to apply to database :param selector: Database name in settings.py module :return: None \"\"\" command . upgrade ( config , revision ) logger . success ( f \"Database { selector } upgraded\" ) @staticmethod def project_setup ( name : str , path : str ) -> None : \"\"\" Creates a project directory with all needed files. :param name: Project's name :param path: Path to project files :return: None :raises BasicManagerException: \"\"\" if path != \".\" : path = os . path . join ( path , name ) if os . path . exists ( path ): raise BasicManagerException ( \"Directory already exists\" ) logger . opt ( colors = True ) . info ( f \"Creating project directory for project \" f \"<yellow> { name } </yellow>\" ) os . mkdir ( path ) for _name , content in FILES . items (): file_path = os . path . join ( path , _name ) if os . sep in _name : os . makedirs ( os . sep . join ( file_path . split ( os . sep )[: - 1 ]), exist_ok = True ) with open ( file_path , \"w\" ) as file : logger . debug ( f \"Creating project file { _name } at { file_path } \" ) file . write ( f \" { content . format ( name = name ) . strip () } \\n \" ) logger . success ( f \"Project structure created for { name } \" ) @staticmethod @show_observer_catalogue def observe_catalogue ( ** context ) -> dict : \"\"\" Pass context dict to illuminate.decorators.cli.show_observe_catalogue. :return: dict \"\"\" return context @show_logo @show_info def observe_start ( self ) -> None : \"\"\" Starts producer/consumer ETL process. :return: None \"\"\" io_loop = ioloop . IOLoop . current () io_loop . run_sync ( self . _observe_start ) async def __start ( self ) -> None : \"\"\" Initializes Adapters and Observers and pass initial Observation objects to self.__observation. :return: None \"\"\" for adapter in self . adapters : self . _adapters . append ( adapter ( manager = self )) logger . opt ( colors = True ) . info ( f \"Adapter <yellow> { adapter . __name__ } </yellow> initialized\" ) for observer in self . observers : instance = observer ( manager = self ) self . _observers . append ( instance ) logger . opt ( colors = True ) . info ( f \"Observer <yellow> { observer . __name__ } </yellow> initialized\" ) for _observation in instance . initial_observations : await self . __router ( _observation ) async def __router ( self , item : Union [ Exporter , Finding , Observation ] ) -> None : \"\"\" Routes object based on its class to proper queue. :param item: Exporter, Finding or Observation object :return: None \"\"\" if isinstance ( item , Exporter ): await self . __export_queue . put ( item ) elif isinstance ( item , Finding ): if inspect . stack ()[ 1 ][ 3 ] != \"__adaptation\" : await self . __adapt_queue . put ( item ) else : logger . warning ( f \"Findings can only yield Exporters and Observations \" f \"thus rejecting item { item } \" ) elif isinstance ( item , Observation ): _hash = hash ( item ) if _hash not in self . __observing : self . __observing . add ( _hash ) if isinstance ( item , HTTPObservation ) and not item . allowed : return await self . __observe_queue . put ( item ) else : logger . warning ( f \"Manager rejected item { item } due to unsupported \" f \"item type { type ( item ) } \" ) @logger . catch async def __observe ( self ) -> None : \"\"\" Takes Observation object from self.__observe_queue and, after delay, pass it to self.__observation method. :return: None \"\"\" async for item in self . __observe_queue : if not item : return await asyncio . sleep ( self . settings . OBSERVATION_CONFIGURATION [ \"delay\" ] ) await self . __observation_switch ( item ) logger . debug ( f \"Coroutine observed { item } \" ) del item self . __observe_queue . task_done () async def __observe_file ( self , item : FileObservation ) -> None : \"\"\" Calls FileObservation's observe method and pass result to resolve function. :param item: FileObservation object :return: None \"\"\" async with item . observe ( xcom = item . xcom ) as result : await self . __observation_resolve ( result , item . url ) async def __observe_http ( self , item : HTTPObservation ) -> None : \"\"\" Prepares HTTPObservation configuration, calls observe method and pass result to resolve function. :param item: HTTPObservation object :return: None \"\"\" item . configuration = { ** self . settings . OBSERVATION_CONFIGURATION [ \"http\" ], ** item . configuration , } result = await item . observe ( xcom = item . xcom ) await self . __observation_resolve ( result , item . url ) async def __observe_sql ( self , item : SQLObservation ) -> None : \"\"\" Calls SQLObservation's observe method and pass result to resolve function. :param item: SQLObservation object :return: None \"\"\" result = await item . observe ( self . sessions [ item . url ], xcom = item . xcom ) await self . __observation_resolve ( result , f \" { item . url } : { item . query } \" ) async def __observe_splash ( self , item : SplashObservation ) -> None : \"\"\" Prepares SplashObservation configuration, calls observe method and pass result to resolve function. :param item: SplashObservation object :return: None \"\"\" item . configuration = { ** self . settings . OBSERVATION_CONFIGURATION [ \"splash\" ], ** item . configuration , } result = await item . observe ( self . settings . OBSERVATION_CONFIGURATION [ \"http\" ], xcom = item . xcom ) await self . __observation_resolve ( result , item . url ) async def __observation_resolve ( self , result : Union [ None , Result ], url : str ): \"\"\" Resolves Observation. :param result: Result :param url: URL str :return: None \"\"\" if not result : self . __not_observed . add ( url ) return self . __observed . add ( url ) try : if inspect . isawaitable ( result ): await result if inspect . isasyncgen ( result ): async for _item in result : await self . __router ( _item ) except Exception : # noqa stack = traceback . format_exc () . strip () . replace ( \"<\" , \" \\\\ <\" ) logger . opt ( colors = True ) . warning ( \"Observation callback throws the following exception \\n \" f \"<red> { stack } </red>\" ) async def __observation_switch ( self , item : Observation ) -> None : \"\"\" Passes Observation object to proper method based on its class. :param item: Observation object :return: None \"\"\" if isinstance ( item , HTTPObservation ): if isinstance ( item , SplashObservation ): await self . __observe_splash ( item ) else : await self . __observe_http ( item ) elif isinstance ( item , FileObservation ): await self . __observe_file ( item ) elif isinstance ( item , SQLObservation ): await self . __observe_sql ( item ) else : logger . warning ( f \"Observation of a type { type ( item ) } is not supported\" ) @logger . catch async def __adapt ( self ) -> None : \"\"\" Takes Finding object from self.__adapt_queue and pass it to self.__adaptation method. :return: None \"\"\" async for item in self . __adapt_queue : if not item : return await self . __adaptation ( item ) logger . debug ( f \"Coroutine adapted { item } \" ) del item self . __adapt_queue . task_done () async def __adaptation ( self , item : Finding ) -> None : \"\"\" Passes Finding object to Adapter's instance adapt method. :param item: Finding object :return: None \"\"\" for adapter in self . _adapters : for subscriber in adapter . subscribers : if isinstance ( item , subscriber ): try : items = adapter . adapt ( item ) async for _item in items : # type: ignore await self . __router ( _item ) except Exception as exception : logger . warning ( f \" { self } .adapt() -> { exception } \" ) @logger . catch async def __export ( self ) -> None : \"\"\" Takes Exporter object from self.__export_queue and pass it to self.__exportation method. :return: None \"\"\" async for item in self . __export_queue : if not item : return await self . __export_to ( item ) logger . debug ( f \"Coroutine exported { item } \" ) del item self . __export_queue . task_done () async def __export_to ( self , item : Exporter ) -> None : \"\"\" Passes Exporter object to proper method based on its class. :param item: Exporter object :return: None \"\"\" if isinstance ( item , ( InfluxDBExporter , SQLExporter )): await self . __export_to_database ( item ) async def __export_to_database ( self , item : Union [ InfluxDBExporter , SQLExporter ] ) -> None : \"\"\" Acquires database session based on Exporter's attributes and pass it to Exporter's export method. :param item: InfluxDBExporter or SQLExporter object :return: None \"\"\" try : session = self . sessions [ item . name ] await item . export ( session ) self . __exported . add ( item ) except BasicExporterException : pass except KeyError : logger . warning ( f \"Database { item . name } of is not found in context\" ) @logger . catch async def _observe_start ( self ) -> None : \"\"\" Starts producer/consumer ETL process. :return: None \"\"\" self . adapters . sort ( key = lambda x : x . priority , reverse = True ) _adapters = self . settings . CONCURRENCY [ \"adapters\" ] _exporters = self . settings . CONCURRENCY [ \"exporters\" ] _obs = self . settings . CONCURRENCY [ \"observations\" ] adapters = gen . multi ([ self . __adapt () for _ in range ( _adapters )]) exporters = gen . multi ([ self . __export () for _ in range ( _exporters )]) observations = gen . multi ([ self . __observe () for _ in range ( _obs )]) await self . __start () await self . __observe_queue . join () await self . __adapt_queue . join () await self . __export_queue . join () for _ in range ( _obs ): await self . __observe_queue . put ( None ) for _ in range ( _adapters ): await self . __adapt_queue . put ( None ) for _ in range ( _exporters ): await self . __export_queue . put ( None ) await adapters await exporters await observations for session in self . sessions : if isinstance ( self . sessions [ session ], InfluxDBClient ): await self . sessions [ session ] . close () # type: ignore","title":"Manager"},{"location":"core/#illuminate.manager.manager.Manager.__init__","text":"Manager's init method. :param adapters: List of Adapters found in project files :param name: Project's name :param observers: List of Observers found in project files after filtering :param path: Path to project files :param sessions: Database sessions :param settings: Project's settings.py module Source code in illuminate/manager/manager.py def __init__ ( self , adapters : list [ Type [ Adapter ]], name : str , observers : list [ Type [ Observer ]], path : str , sessions : dict [ str , Union [ Type [ AsyncSession ], InfluxDBClient ]], settings : ModuleType , * args , ** kwargs , ): \"\"\" Manager's __init__ method. :param adapters: List of Adapters found in project files :param name: Project's name :param observers: List of Observers found in project files after filtering :param path: Path to project files :param sessions: Database sessions :param settings: Project's settings.py module \"\"\" self . adapters = adapters self . name = name self . observers = observers self . path = path self . sessions = sessions self . settings = settings self . _adapters : list [ Adapter ] = [] self . _observers : list [ Observer ] = [] self . __observe_queue : queues . Queue = queues . Queue () self . __adapt_queue : queues . Queue = queues . Queue () self . __export_queue : queues . Queue = queues . Queue () self . __exported : set = set () self . __not_observed : set = set () self . __observed : set = set () self . __observing : set = set ()","title":"__init__()"},{"location":"core/#illuminate.manager.manager.Manager.db_populate","text":"Populates database with fixtures. :param fixtures: Tuple of fixture files :param selector: Database name in settings.py module :param url: SQLAlchemy Database URL :return: None Source code in illuminate/manager/manager.py @staticmethod @adapt ( \"populate\" ) def db_populate ( fixtures : tuple [ str ], selector : str , url : str , ) -> None : \"\"\" Populates database with fixtures. :param fixtures: Tuple of fixture files :param selector: Database name in settings.py module :param url: SQLAlchemy Database URL :return: None \"\"\" models = Assistant . provide_models () table_data = {} for _file in fixtures : with open ( _file , \"r\" ) as file : # type: ignore content = json . load ( file ) # type: ignore for table in content : table_data . update ({ table [ \"name\" ]: table [ \"data\" ]}) with Session ( create_engine ( url )) as session : for model in models : if model . __tablename__ in table_data : # type: ignore data = table_data [ model . __tablename__ ] # type: ignore for record in data : session . add ( model ( ** record )) # type: ignore logger . debug ( f \"Row { record } added to \" # type: ignore f \"table buffer { model . __tablename__ } \" ) session . commit () logger . success ( f \"Database { selector } populated\" )","title":"db_populate()"},{"location":"core/#illuminate.manager.manager.Manager.db_revision","text":"Creates Alembic's revision file in migration directory. :param config: Alembic's configuration object :param revision: Parent revision :return: None Source code in illuminate/manager/manager.py @staticmethod @adapt ( \"revision\" ) def db_revision ( config : Config , revision : str , ) -> None : \"\"\" Creates Alembic's revision file in migration directory. :param config: Alembic's configuration object :param revision: Parent revision :return: None \"\"\" command . revision ( config , autogenerate = True , head = revision , ) logger . success ( \"Revision created\" )","title":"db_revision()"},{"location":"core/#illuminate.manager.manager.Manager.db_upgrade","text":"Applies migration file to a database. :param config: Alembic's configuration object :param revision: Revision to apply to database :param selector: Database name in settings.py module :return: None Source code in illuminate/manager/manager.py @staticmethod @adapt ( \"upgrade\" ) def db_upgrade ( config : Config , revision : str , selector : str , ) -> None : \"\"\" Applies migration file to a database. :param config: Alembic's configuration object :param revision: Revision to apply to database :param selector: Database name in settings.py module :return: None \"\"\" command . upgrade ( config , revision ) logger . success ( f \"Database { selector } upgraded\" )","title":"db_upgrade()"},{"location":"core/#illuminate.manager.manager.Manager.observe_catalogue","text":"Pass context dict to illuminate.decorators.cli.show_observe_catalogue. :return: dict Source code in illuminate/manager/manager.py @staticmethod @show_observer_catalogue def observe_catalogue ( ** context ) -> dict : \"\"\" Pass context dict to illuminate.decorators.cli.show_observe_catalogue. :return: dict \"\"\" return context","title":"observe_catalogue()"},{"location":"core/#illuminate.manager.manager.Manager.observe_start","text":"Starts producer/consumer ETL process. :return: None Source code in illuminate/manager/manager.py @show_logo @show_info def observe_start ( self ) -> None : \"\"\" Starts producer/consumer ETL process. :return: None \"\"\" io_loop = ioloop . IOLoop . current () io_loop . run_sync ( self . _observe_start )","title":"observe_start()"},{"location":"core/#illuminate.manager.manager.Manager.project_setup","text":"Creates a project directory with all needed files. :param name: Project's name :param path: Path to project files :return: None :raises BasicManagerException: Source code in illuminate/manager/manager.py @staticmethod def project_setup ( name : str , path : str ) -> None : \"\"\" Creates a project directory with all needed files. :param name: Project's name :param path: Path to project files :return: None :raises BasicManagerException: \"\"\" if path != \".\" : path = os . path . join ( path , name ) if os . path . exists ( path ): raise BasicManagerException ( \"Directory already exists\" ) logger . opt ( colors = True ) . info ( f \"Creating project directory for project \" f \"<yellow> { name } </yellow>\" ) os . mkdir ( path ) for _name , content in FILES . items (): file_path = os . path . join ( path , _name ) if os . sep in _name : os . makedirs ( os . sep . join ( file_path . split ( os . sep )[: - 1 ]), exist_ok = True ) with open ( file_path , \"w\" ) as file : logger . debug ( f \"Creating project file { _name } at { file_path } \" ) file . write ( f \" { content . format ( name = name ) . strip () } \\n \" ) logger . success ( f \"Project structure created for { name } \" )","title":"project_setup()"},{"location":"decorators/","text":"illuminate . decorators . cli . adapt ( command : str ) -> Callable Adapts Manager's static methods to accept cli arguments. :param command: Command string :return: Manager's static method wrapper Source code in illuminate/decorators/cli.py def adapt ( command : str ) -> Callable : \"\"\" Adapts Manager's static methods to accept cli arguments. :param command: Command string :return: Manager's static method wrapper \"\"\" def decorator ( func : Callable ) -> Callable : \"\"\" Outer wrapper responsible for control flow. :param func: The function to be adapted :return: The wrapped function with adapted arguments \"\"\" if command == \"populate\" : @functools . wraps ( func ) def wrapper ( fixtures : tuple [ str ], selector : str , url : str , * args , ** kwargs ) -> None : \"\"\" Adapts Manager's db_populate method to accept cli arguments. :param fixtures: Tuple of fixture files :param selector: Database name in settings.py module :param url: SQLAlchemy Database URL :return: None \"\"\" try : func ( fixtures , selector , url or Assistant . _provide_db_url ( selector ), * args , ** kwargs , ) except NoSuchModuleError : raise BasicManagerException ( \"Command populate can only be performed on SQL \" f \"database, { selector } is not supported SQL database\" ) elif command == \"revision\" : @functools . wraps ( func ) def wrapper ( path : str , revision : str , selector : str , url : str , * args , ** kwargs , ) -> None : \"\"\" Adapts Manager's db_revision method to accept cli arguments. :param path: Migration directory path :param revision: Parent revision :param selector: Database name in settings.py module :param url: SQLAlchemy Database URL :return: None \"\"\" try : config = Assistant . provide_alembic_config ( path , selector , url ) func ( config , revision , * args , ** kwargs ) except NoSuchModuleError : raise BasicManagerException ( \"Command revision can only be performed on SQL \" f \"database, { selector } is not supported SQL database\" ) elif command == \"upgrade\" : @functools . wraps ( func ) def wrapper ( path : str , revision : str , selector : str , url : str , * args , ** kwargs , ) -> None : \"\"\" Adapts Manager's db_upgrade method to accept cli arguments. :param path: Migration directory path :param revision: Parent revision :param selector: Database name in settings.py module :param url: SQLAlchemy Database URL :return: None \"\"\" try : config = Assistant . provide_alembic_config ( path , selector , url ) func ( config , revision , selector , * args , ** kwargs ) except NoSuchModuleError : raise BasicManagerException ( \"Command upgrade can only be performed on SQL \" f \"database, { selector } is not supported SQL database\" ) else : logger . warning ( f \"Decorated command { command } is not supported\" ) @functools . wraps ( func ) def wrapper ( * args , ** kwargs ) -> None : \"\"\" Does nothing. :return: None \"\"\" func ( * args , ** kwargs ) return wrapper return decorator illuminate . decorators . logging . show_info ( func : Callable ) -> Callable Displays ETL process information. :param func: Manager's public method :return: Manager's public method wrapper Source code in illuminate/decorators/logging.py def show_info ( func : Callable ) -> Callable : \"\"\" Displays ETL process information. :param func: Manager's public method :return: Manager's public method wrapper \"\"\" @functools . wraps ( func ) def wrapper ( self : Manager ) -> None : \"\"\" Displays ETL process information. :param self: Manager object :return: None \"\"\" logger . info ( \"Process started\" ) start = default_timer () log_context ( self ) log_settings ( self ) func ( self ) end = default_timer () - start log_results ( self ) logger . opt ( colors = True ) . info ( f \"Process finished in <yellow> { end : .2f } </yellow> seconds\" ) def log_context ( self : Manager ) -> None : \"\"\" Displays ETL context information. :param self: Manager object :return: None \"\"\" logger . opt ( colors = True ) . info ( f \"Project files for project \" f \"<yellow> { self . name } </yellow> loaded into context\" ) logger . info ( f \"Adapters discovered { [ i for i in self . adapters ] } \" ) logger . info ( f \"Models discovered { [ locate ( i ) for i in self . settings . MODELS ] } \" ) logger . info ( f \"Observers discovered { [ i for i in self . observers ] } \" ) def log_results ( self : Manager ) -> None : \"\"\" Displays ETL results information. :param self: Manager object :return: None \"\"\" logger . success ( \"Results gathered\" ) logger . opt ( colors = True ) . info ( f \"<yellow>Unsuccessful</yellow> observations: \" f \"<magenta> { len ( self . not_observed ) } </magenta>\" ) logger . debug ( f \"Unsuccessful attempts { self . not_observed } \" ) logger . opt ( colors = True ) . info ( f \"<yellow>Successful</yellow> observations: \" f \"<magenta> { len ( self . observed ) - len ( self . not_observed ) } </magenta>\" ) logger . opt ( colors = True ) . info ( f \"Number of <yellow>exports</yellow>: \" f \"<magenta> { len ( self . exported ) } </magenta>\" ) def log_settings ( self : Manager ) -> None : \"\"\" Displays ETL settings information. :param self: Manager object :return: None \"\"\" settings_conn = self . settings . CONCURRENCY settings_db = self . settings . DB . copy () for db in settings_db : settings_db [ db ][ \"pass\" ] = \"****\" # nosec settings_obs = self . settings . OBSERVATION_CONFIGURATION . copy () settings_obs [ \"http\" ][ \"auth_password\" ] = \"****\" # nosec logger . debug ( f \"Concurrency settings { settings_conn } \" ) logger . debug ( f \"Database settings { settings_db } \" ) logger . debug ( f \"Observation settings { settings_obs } \" ) return wrapper illuminate . decorators . logging . show_logo ( func : Callable ) -> Callable Displays framework's logo. :param func: Manager's public method :return: Manager's public method wrapper Source code in illuminate/decorators/logging.py def show_logo ( func : Callable ) -> Callable : \"\"\" Displays framework's logo. :param func: Manager's public method :return: Manager's public method wrapper \"\"\" @functools . wraps ( func ) def wrapper ( * args , ** kwargs ) -> None : \"\"\" Displays framework's logo. :return: None \"\"\" logo = f \"<fg { LOGO_COLOR } > { LOGO } </fg { LOGO_COLOR } >\" logger . opt ( colors = True ) . success ( logo ) func ( * args , ** kwargs ) return wrapper illuminate . decorators . logging . show_observer_catalogue ( func : Callable ) -> Callable Displays Observers found in project files. :param func: CLI's function :return: CLI's function wrapper Source code in illuminate/decorators/logging.py def show_observer_catalogue ( func : Callable ) -> Callable : \"\"\" Displays Observers found in project files. :param func: CLI's function :return: CLI's function wrapper \"\"\" @functools . wraps ( func ) def wrapper ( * args , ** kwargs ) -> None : \"\"\" Displays Observers found in project files. :return: None \"\"\" context = func ( * args , ** kwargs ) if not context [ \"observers\" ]: logger . info ( \"No observers found\" ) outputs = [] for observer in context [ \"observers\" ]: _observer = observer () _io = _observer . initial_observations outputs . append ( f \"<yellow> { _observer . __class__ } </yellow> -> \" f \"<cyan> { [( i . url , i . _callback . __name__ ) for i in _io ] } </cyan>\" ) for output in outputs : logger . opt ( colors = True ) . info ( output ) return wrapper","title":"Decorators"},{"location":"decorators/#illuminate.decorators.cli.adapt","text":"Adapts Manager's static methods to accept cli arguments. :param command: Command string :return: Manager's static method wrapper Source code in illuminate/decorators/cli.py def adapt ( command : str ) -> Callable : \"\"\" Adapts Manager's static methods to accept cli arguments. :param command: Command string :return: Manager's static method wrapper \"\"\" def decorator ( func : Callable ) -> Callable : \"\"\" Outer wrapper responsible for control flow. :param func: The function to be adapted :return: The wrapped function with adapted arguments \"\"\" if command == \"populate\" : @functools . wraps ( func ) def wrapper ( fixtures : tuple [ str ], selector : str , url : str , * args , ** kwargs ) -> None : \"\"\" Adapts Manager's db_populate method to accept cli arguments. :param fixtures: Tuple of fixture files :param selector: Database name in settings.py module :param url: SQLAlchemy Database URL :return: None \"\"\" try : func ( fixtures , selector , url or Assistant . _provide_db_url ( selector ), * args , ** kwargs , ) except NoSuchModuleError : raise BasicManagerException ( \"Command populate can only be performed on SQL \" f \"database, { selector } is not supported SQL database\" ) elif command == \"revision\" : @functools . wraps ( func ) def wrapper ( path : str , revision : str , selector : str , url : str , * args , ** kwargs , ) -> None : \"\"\" Adapts Manager's db_revision method to accept cli arguments. :param path: Migration directory path :param revision: Parent revision :param selector: Database name in settings.py module :param url: SQLAlchemy Database URL :return: None \"\"\" try : config = Assistant . provide_alembic_config ( path , selector , url ) func ( config , revision , * args , ** kwargs ) except NoSuchModuleError : raise BasicManagerException ( \"Command revision can only be performed on SQL \" f \"database, { selector } is not supported SQL database\" ) elif command == \"upgrade\" : @functools . wraps ( func ) def wrapper ( path : str , revision : str , selector : str , url : str , * args , ** kwargs , ) -> None : \"\"\" Adapts Manager's db_upgrade method to accept cli arguments. :param path: Migration directory path :param revision: Parent revision :param selector: Database name in settings.py module :param url: SQLAlchemy Database URL :return: None \"\"\" try : config = Assistant . provide_alembic_config ( path , selector , url ) func ( config , revision , selector , * args , ** kwargs ) except NoSuchModuleError : raise BasicManagerException ( \"Command upgrade can only be performed on SQL \" f \"database, { selector } is not supported SQL database\" ) else : logger . warning ( f \"Decorated command { command } is not supported\" ) @functools . wraps ( func ) def wrapper ( * args , ** kwargs ) -> None : \"\"\" Does nothing. :return: None \"\"\" func ( * args , ** kwargs ) return wrapper return decorator","title":"adapt()"},{"location":"decorators/#illuminate.decorators.logging.show_info","text":"Displays ETL process information. :param func: Manager's public method :return: Manager's public method wrapper Source code in illuminate/decorators/logging.py def show_info ( func : Callable ) -> Callable : \"\"\" Displays ETL process information. :param func: Manager's public method :return: Manager's public method wrapper \"\"\" @functools . wraps ( func ) def wrapper ( self : Manager ) -> None : \"\"\" Displays ETL process information. :param self: Manager object :return: None \"\"\" logger . info ( \"Process started\" ) start = default_timer () log_context ( self ) log_settings ( self ) func ( self ) end = default_timer () - start log_results ( self ) logger . opt ( colors = True ) . info ( f \"Process finished in <yellow> { end : .2f } </yellow> seconds\" ) def log_context ( self : Manager ) -> None : \"\"\" Displays ETL context information. :param self: Manager object :return: None \"\"\" logger . opt ( colors = True ) . info ( f \"Project files for project \" f \"<yellow> { self . name } </yellow> loaded into context\" ) logger . info ( f \"Adapters discovered { [ i for i in self . adapters ] } \" ) logger . info ( f \"Models discovered { [ locate ( i ) for i in self . settings . MODELS ] } \" ) logger . info ( f \"Observers discovered { [ i for i in self . observers ] } \" ) def log_results ( self : Manager ) -> None : \"\"\" Displays ETL results information. :param self: Manager object :return: None \"\"\" logger . success ( \"Results gathered\" ) logger . opt ( colors = True ) . info ( f \"<yellow>Unsuccessful</yellow> observations: \" f \"<magenta> { len ( self . not_observed ) } </magenta>\" ) logger . debug ( f \"Unsuccessful attempts { self . not_observed } \" ) logger . opt ( colors = True ) . info ( f \"<yellow>Successful</yellow> observations: \" f \"<magenta> { len ( self . observed ) - len ( self . not_observed ) } </magenta>\" ) logger . opt ( colors = True ) . info ( f \"Number of <yellow>exports</yellow>: \" f \"<magenta> { len ( self . exported ) } </magenta>\" ) def log_settings ( self : Manager ) -> None : \"\"\" Displays ETL settings information. :param self: Manager object :return: None \"\"\" settings_conn = self . settings . CONCURRENCY settings_db = self . settings . DB . copy () for db in settings_db : settings_db [ db ][ \"pass\" ] = \"****\" # nosec settings_obs = self . settings . OBSERVATION_CONFIGURATION . copy () settings_obs [ \"http\" ][ \"auth_password\" ] = \"****\" # nosec logger . debug ( f \"Concurrency settings { settings_conn } \" ) logger . debug ( f \"Database settings { settings_db } \" ) logger . debug ( f \"Observation settings { settings_obs } \" ) return wrapper","title":"show_info()"},{"location":"decorators/#illuminate.decorators.logging.show_logo","text":"Displays framework's logo. :param func: Manager's public method :return: Manager's public method wrapper Source code in illuminate/decorators/logging.py def show_logo ( func : Callable ) -> Callable : \"\"\" Displays framework's logo. :param func: Manager's public method :return: Manager's public method wrapper \"\"\" @functools . wraps ( func ) def wrapper ( * args , ** kwargs ) -> None : \"\"\" Displays framework's logo. :return: None \"\"\" logo = f \"<fg { LOGO_COLOR } > { LOGO } </fg { LOGO_COLOR } >\" logger . opt ( colors = True ) . success ( logo ) func ( * args , ** kwargs ) return wrapper","title":"show_logo()"},{"location":"decorators/#illuminate.decorators.logging.show_observer_catalogue","text":"Displays Observers found in project files. :param func: CLI's function :return: CLI's function wrapper Source code in illuminate/decorators/logging.py def show_observer_catalogue ( func : Callable ) -> Callable : \"\"\" Displays Observers found in project files. :param func: CLI's function :return: CLI's function wrapper \"\"\" @functools . wraps ( func ) def wrapper ( * args , ** kwargs ) -> None : \"\"\" Displays Observers found in project files. :return: None \"\"\" context = func ( * args , ** kwargs ) if not context [ \"observers\" ]: logger . info ( \"No observers found\" ) outputs = [] for observer in context [ \"observers\" ]: _observer = observer () _io = _observer . initial_observations outputs . append ( f \"<yellow> { _observer . __class__ } </yellow> -> \" f \"<cyan> { [( i . url , i . _callback . __name__ ) for i in _io ] } </cyan>\" ) for output in outputs : logger . opt ( colors = True ) . info ( output ) return wrapper","title":"show_observer_catalogue()"},{"location":"exceptions/","text":"illuminate.exceptions.basic.BasicIlluminateException ( Exception ) Base Illuminate exception class. Source code in illuminate/exceptions/basic.py class BasicIlluminateException ( Exception ): \"\"\"Base Illuminate exception class.\"\"\" illuminate.exceptions.adapter.BasicAdapterException ( BasicIlluminateException ) Base Adapter exception class. Source code in illuminate/exceptions/adapter.py class BasicAdapterException ( BasicIlluminateException ): \"\"\"Base Adapter exception class.\"\"\" illuminate.exceptions.exporter.BasicExporterException ( BasicIlluminateException ) Base Exporter exception class. Source code in illuminate/exceptions/exporter.py class BasicExporterException ( BasicIlluminateException ): \"\"\"Base Exporter exception class.\"\"\" illuminate.exceptions.manager.BasicManagerException ( BasicIlluminateException ) Base Manager exception class. Source code in illuminate/exceptions/manager.py class BasicManagerException ( BasicIlluminateException ): \"\"\"Base Manager exception class.\"\"\" illuminate.exceptions.observation.BasicObservationException ( BasicIlluminateException ) Base Observation exception class. Source code in illuminate/exceptions/observation.py class BasicObservationException ( BasicIlluminateException ): \"\"\"Base Observation exception class.\"\"\" illuminate.exceptions.observer.BasicObserverException ( BasicIlluminateException ) Base Observer exception class. Source code in illuminate/exceptions/observer.py class BasicObserverException ( BasicIlluminateException ): \"\"\"Base Observer exception class.\"\"\"","title":"Exceptions"},{"location":"exceptions/#illuminate.exceptions.basic.BasicIlluminateException","text":"Base Illuminate exception class. Source code in illuminate/exceptions/basic.py class BasicIlluminateException ( Exception ): \"\"\"Base Illuminate exception class.\"\"\"","title":"BasicIlluminateException"},{"location":"exceptions/#illuminate.exceptions.adapter.BasicAdapterException","text":"Base Adapter exception class. Source code in illuminate/exceptions/adapter.py class BasicAdapterException ( BasicIlluminateException ): \"\"\"Base Adapter exception class.\"\"\"","title":"BasicAdapterException"},{"location":"exceptions/#illuminate.exceptions.exporter.BasicExporterException","text":"Base Exporter exception class. Source code in illuminate/exceptions/exporter.py class BasicExporterException ( BasicIlluminateException ): \"\"\"Base Exporter exception class.\"\"\"","title":"BasicExporterException"},{"location":"exceptions/#illuminate.exceptions.manager.BasicManagerException","text":"Base Manager exception class. Source code in illuminate/exceptions/manager.py class BasicManagerException ( BasicIlluminateException ): \"\"\"Base Manager exception class.\"\"\"","title":"BasicManagerException"},{"location":"exceptions/#illuminate.exceptions.observation.BasicObservationException","text":"Base Observation exception class. Source code in illuminate/exceptions/observation.py class BasicObservationException ( BasicIlluminateException ): \"\"\"Base Observation exception class.\"\"\"","title":"BasicObservationException"},{"location":"exceptions/#illuminate.exceptions.observer.BasicObserverException","text":"Base Observer exception class. Source code in illuminate/exceptions/observer.py class BasicObserverException ( BasicIlluminateException ): \"\"\"Base Observer exception class.\"\"\"","title":"BasicObserverException"},{"location":"future/","text":"Disclaimer Version 0.X will be a playground where functionalities are added, until there is enough knowledge for better API. Even now some inconsistencies are obvious. For example, all Observers and Adapters are picked up by Assistant class but models are specified in settings.py module. This said, you are warned, version 0.X comes with no guarantees. Your projects will be completely broken when version 1.X hits the shelves. Future releases The next few minor releases would focus on additional Exporter and Observation classes. Everything async is a good candidate if it used in ETL. It should also focus on integration with cloud service providers, to include their services as Exporter and Observation classes Small list of features would include: Exporter Classes AWSS3Exporter - AWS S3 cloud service integration exporter FileExporter - File exporter InfluxDBExporter - InfluxDB exporter HTTPExporter - HTTP exporter KafkaExporter - Kafka producer exporter SplashExporter - Web 2.0 proxy js renderer exporter Observation Classes AWSS3Observation - AWS S3 cloud service integration observation FileObservation - File observation InfluxDBObservation - InfluxDB observation KafkaObservation - Kafka consumer observation SplashObservation - Web 2.0 proxy js renderer observation SQLObservation - SQL observation Future needs you! Consider becoming a contributor.","title":"Future?"},{"location":"future/#disclaimer","text":"Version 0.X will be a playground where functionalities are added, until there is enough knowledge for better API. Even now some inconsistencies are obvious. For example, all Observers and Adapters are picked up by Assistant class but models are specified in settings.py module. This said, you are warned, version 0.X comes with no guarantees. Your projects will be completely broken when version 1.X hits the shelves.","title":"Disclaimer"},{"location":"future/#future-releases","text":"The next few minor releases would focus on additional Exporter and Observation classes. Everything async is a good candidate if it used in ETL. It should also focus on integration with cloud service providers, to include their services as Exporter and Observation classes Small list of features would include: Exporter Classes AWSS3Exporter - AWS S3 cloud service integration exporter FileExporter - File exporter InfluxDBExporter - InfluxDB exporter HTTPExporter - HTTP exporter KafkaExporter - Kafka producer exporter SplashExporter - Web 2.0 proxy js renderer exporter Observation Classes AWSS3Observation - AWS S3 cloud service integration observation FileObservation - File observation InfluxDBObservation - InfluxDB observation KafkaObservation - Kafka consumer observation SplashObservation - Web 2.0 proxy js renderer observation SQLObservation - SQL observation","title":"Future releases"},{"location":"future/#future-needs-you","text":"Consider becoming a contributor.","title":"Future needs you!"},{"location":"structure/","text":"If you have followed steps from the home page, and created a project inside a tutorial/ directory there will be the following project structure inside that directory. tutorial \u251c\u2500\u2500 adapters \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 example.py \u251c\u2500\u2500 exporters \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 example.py \u251c\u2500\u2500 findings \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 example.py \u251c\u2500\u2500 fixtures \u2502 \u2514\u2500\u2500 example.json \u251c\u2500\u2500 migrations \u2502 \u251c\u2500\u2500 versions \u2502 \u251c\u2500\u2500 env.py \u2502 \u2514\u2500\u2500 script.py.mako \u251c\u2500\u2500 models \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 example.py \u251c\u2500\u2500 observers \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 example.py \u251c\u2500\u2500 docker-compose.yaml \u2514\u2500\u2500 settings.py Observers observers/ package is a place where you write your ETL configuration classes. Once illuminate observe start command is issued, all classes found in the package which name starts with the word \"Observer\" will be added into context and initialized. from __future__ import annotations from collections.abc import AsyncGenerator , Generator from typing import Optional , Union from urllib.parse import urldefrag from urllib.parse import urljoin from bs4 import BeautifulSoup from illuminate.manager import Manager from illuminate.observation import HTTPObservation from illuminate.observer import Observer from tornado.httpclient import HTTPResponse from exporters.example import ExporterInfluxDBExample from exporters.example import ExporterSQLExample from findings.example import FindingExample def _create_soup ( response : HTTPResponse ) -> BeautifulSoup : html = response . body . decode ( errors = \"ignore\" ) soup = BeautifulSoup ( html , \"html.parser\" ) return soup def _extract_hrefs ( soup : BeautifulSoup , url : str ) -> Generator [ str , None ]: links = soup . find_all ( \"a\" ) for link in links : _url = link . get ( \"href\" ) if _url : yield urljoin ( url , urldefrag ( _url )[ 0 ]) class ObserverExample ( Observer ): \"\"\" Observer is ETL configuration class. It represents entry point, and it defines the flow with observe, and any additional method. Once initialized by the framework, it will fill an observation queue with objects from Observer's initial_observation collection, starting the whole process. Note: Multiple Observers can exist in the same project. \"\"\" ALLOWED : Union [ list [ str ], tuple [ str ]] = ( \"https://webscraper.io/\" ,) \"\"\" Collection of strings evaluated against URL to determent if URL is allowed to be observed. If empty, no Observation wide restrictions are forced. \"\"\" LABELS : dict = { \"tag\" : \"example\" } \"\"\"Observer's labels.\"\"\" NAME : str = \"example\" \"\"\"Observer's name.\"\"\" def __init__ ( self , manager : Optional [ Manager ] = None ): \"\"\" Collection initial_observations is de facto entry point. It must contain Observation objects initialized with URL, allowed list of strings and callback method. If Observation's URL starts with element in allowed collection, it will be performed. Otherwise, it is rejected. Manager's instance (object that is running whole process) is passed as an argument when initializing Observers. This allows Observer object to interact with Manager object attributes, like database sessions or queues for advanced ETL flows, by simply asking for self.manager.sessions[\"postgresql\"][\"main\"] to acquire async database session defined in tutorial/settings.py. \"\"\" super () . __init__ ( manager ) self . initial_observations = [ HTTPObservation ( \"https://webscraper.io/\" , allowed = self . ALLOWED , callback = self . observe , ), ] async def observe ( self , response : HTTPResponse , * args , ** kwargs ) -> AsyncGenerator [ Union [ ExporterInfluxDBExample , ExporterSQLExample , FindingExample , HTTPObservation , ], None , ]: \"\"\" ETL flow is regulated by a yielded object type of Observation's callback method. Each object type corresponds to ETL stage: * Observation -> Extract * Finding -> Transform * Exporter -> Load In the example below, initial HTTPObservation returned Tornado's HTTP response object that was used to extract all hrefs from HTML. These hrefs will be used as URLs for new HTTPObservations, using the same observe method as a callback and same allowed collection. Finally, Finding object is yielded, representing a desired data. This flow, with everything set, represents a simple web scraper that will visit every page found on a domain, and take page's title and URL as desired data. Tip: If there is no need for some further data enrichment or manipulation, yield Exporter object instead of Finding object. For reference check tutorial/adapters/example.py. Note: Illuminate takes care of tracking what resources were already requested, avoiding duplication. Resource check pool is shared between Observers, avoiding overlapping. \"\"\" soup = _create_soup ( response ) hrefs = _extract_hrefs ( soup , response . effective_url ) for href in hrefs : yield HTTPObservation ( href , allowed = self . ALLOWED , callback = self . observe , ) yield FindingExample ( response . request_time , soup . title . text , response . effective_url ) Observer vs Observation Observer is ETL configuration class. It introduces Observation objects, in this case HTTPObservation objects, through initial_observations , to a framework. It also should be used (not forced, but suggested) to contain all callback methods used by Observation objects. Observation class is a type of source that will be read. Once the data is pulled, it will provide a response object to a callback function that will asynchronously generate additional object related to ETL flow, using Illuminate ETL Mapping Classes. NOTE : You can register any async generator as HTTPObservation.callback . For simplicity, we will use ObserverExample.observe method. ETL Mapping Classes Each stage in ETL flow is represented by a class from Illuminate framework. Extract is represented with Observation Transform is represented with Adapter Load is represented with Exporter If a response object from initial Observation is just a step before the data you want to export, yield new Observation with same or different callback, allowing you to construct a complex set of rules. If a response object holds the data you want to adapt, yield Finding object. It will be picked up by Adapter instances that will perform adapt method with Finding object passed as argument if the condition is met. If a response object is something that requires minimal transformation, or it could be used raw, you can yield Exporter object and skip complex adaptation. Findings findings/ package is a place where you write your data classes. This class is meant to be picked up by a framework and passed to Adapter instance, to perform actual adaptation up on data, and yield Exporter or Observation objects. It can only be yielded by Observation object's callback , in our example project, it will be yield by ExampleObserver.observe method. from dataclasses import dataclass from dataclasses import field from illuminate.observer import Finding @dataclass ( frozen = True , order = True ) class FindingExample ( Finding ): \"\"\" Finding is a data class, meant to hold raw data extracted by Observation's callback. Finding will be passed to Adapter object's adapt method if it is subscribed to Adapter. Check tutorial/adapters/example.py to learn more about subscription. \"\"\" load_time : float = field () title : str = field () url : str = field () Model models/ package is a place where you write your database model classes. Models are used by SQLExporter in our example and are recommended method of writing and reading data from SQL database. NOTE : SQLObservation class is not yet introduced to the framework. from sqlalchemy import Column , Float , Integer , String from models import Base class ModelExample ( Base ): \"\"\" SQLAlchemy model used by SQLExporter object. For more information about SQLExporter class check tutorial/exporters/example.py. \"\"\" __tablename__ = \"tutorial\" id : int = Column ( Integer , primary_key = True ) load_time : float = Column ( Float ) title : str = Column ( String ) url : str = Column ( String ) def __repr__ ( self ): \"\"\"ModelExample's __repr__ method.\"\"\" return ( f 'ModelExample(load_time= { self . load_time } ,' f 'title=\" { self . title } \",url=\" { self . url } \")' ) Adapter adapters/ package is a place where you write your transformation classes. Once illuminate observe start command is issued, all classes found in the package which name starts with the word \"Adapter\" will be added into context and initialized. Once the framework gets Finding object from a queue, it will check if object is \"subscribed\" to Adapter . If object is subscribed, the framework will pass it to adapt method that will yield Exporter or Observation objects. Method adapt is where you implement your adaptation rules. In the following example, method adapt is just used to create a model instance to be passed to SQLExpoter instance, yet to be saved later into the database. Each Adapter object must contain a tuple of Finding classes, called subscribers that will be passed to adapt method. Others will be rejected by a framework. Since there could be multiple Adapter classes with various implementation of adapt method, if Finding is subscribed to multiple Adapters , priority attribute will determent which adapt method should be called first. NOTE : Method adapt can't yield Findings . from __future__ import annotations from collections.abc import AsyncGenerator from typing import Type , Union from illuminate.adapter import Adapter from illuminate.observation import FileObservation from illuminate.observation import HTTPObservation from illuminate.observation import SQLObservation from illuminate.observation import SplashObservation from illuminate.observer import Finding from exporters.example import ExporterInfluxDBExample from exporters.example import ExporterSQLExample from findings.example import FindingExample from models.example import ModelExample class AdapterExample ( Adapter ): \"\"\" Adapter class is responsible for turning Finding objects into Exporter or Observation objects, and yielding them when adapt method is called. It is also designated to be a place where any additional enrichment of data should be performed, calling external services with some async library. If additional data can be used to construct URL, additional Observations can be yielded. For more information how to yield Observation object, check tutorial/observers/example.py. Attribute subscribers is a collection of Finding classes that will be processed by Adapter. If Finding is subscribed to two or more Adapters, priority in adaptation will be give to Adapter with higher priority score. Manager's instance (object that is running whole process) is passed as an argument when initializing Adapters. This allows Adapter object to interact with Manager object attributes, like database sessions or queues for advanced ETL flows, by simply asking for self.manager.sessions[\"postgresql\"][\"main\"] to acquire async database session defined in tutorial/settings.py. Note: Method adapt can not yield Findings. \"\"\" priority : int = 10 subscribers : tuple [ Type [ Finding ]] = ( FindingExample ,) async def adapt ( self , finding : FindingExample , * args , ** kwargs ) -> AsyncGenerator [ Union [ ExporterInfluxDBExample , ExporterSQLExample , FileObservation , HTTPObservation , SQLObservation , SplashObservation , ], None , ]: yield ExporterSQLExample ( models = [ ModelExample ( load_time = finding . load_time , title = finding . title , url = finding . url ) ] ) yield ExporterInfluxDBExample ( points = { \"measurement\" : \"tutorial\" , \"tags\" : { \"url\" : finding . url , \"title\" : finding . title }, \"fields\" : { \"load_time\" : finding . load_time }, } ) Exporter exporters/ package is a place where you write your dump classes. from __future__ import annotations from typing import Iterable , Union from illuminate.exporter import InfluxDBExporter from illuminate.exporter import SQLExporter from pandas import DataFrame from models.example import ModelExample class ExporterInfluxDBExample ( InfluxDBExporter ): \"\"\" InfluxDBExporter class will write points to database using session. Points are passed at initialization, while database session is found by name attribute in the pool of existing sessions. Name must co-respond to DB section in tutorial/settings.py. For more information how to initialize InfluxDBExporter class, check tutorial/adapters/example.py \"\"\" name : str = \"measurements\" def __init__ ( self , points : Union [ Union [ DataFrame , dict , str , bytes ], Iterable [ Union [ DataFrame , dict , str , bytes ]], ], ): super () . __init__ ( points ) class ExporterSQLExample ( SQLExporter ): \"\"\" SQLExporter class will commit models to database using session. Models are passed at initialization, while database session is found by name attribute in the pool of existing sessions. Name must co-respond to DB section in tutorial/settings.py. For more information how to initialize SQLExporter class, check tutorial/adapters/example.py \"\"\" name : str = \"main\" def __init__ ( self , models : Union [ list [ ModelExample ], tuple [ ModelExample ]]): super () . __init__ ( models ) In our example, everything is set for Exporter object to fetch a database connection from the framework and use it to facilitate dump to the destination. Since we are writing to SQL database, we will import SQLExporter to inherit from in ExporterExample class. Migrations migrations/ package contains files needed by Alembic to perform database operations. It contains versions directory where migration scripts are held, providing Illuminate with the ability to administer its own databases out of the box. Usually, the content of this directory is not a user's concern. Fixtures Directory fixtures/ holds json files that contain data needed in ETL flow beforehand. This data is injected into the database with illuminate manage database populate cli command. Each object in a list represents a table/model. Key name represents table/model name and data is a list of rows to be inserted with CLI command. [ { \"name\" : \"tutorial\" , \"data\" : [ { \"load_time\" : \"1.0\" , \"url\" : \"https://webscraper.io/\" , \"title\" : \"Web Scraper - The #1 web scraping extension\" }, { \"load_time\" : \"1.0\" , \"url\" : \"https://webscraper.io/tutorials\" , \"title\" : \"Web Scraper Tutorials\" } ] } ] Settings Module settings.py contains all configuration needed to run ETL process. \"\"\" This file represents project tutorial's settings. It will be imported by a framework and used to configure run. The sections are as following: * CONCURRENCY Number of workers per queue type. I/O heavy queues can have more workers assigned to them to exploit longer wait times. * DB Database related data used by SQLAlchemy to acquire sessions. Sessions are obtained at the start of the ETL process and can be accessed by instantiating Manager class and access sessions attribute. * MODELS List of SQLAlchemy models affected by illuminate cli when invoking 'db revision', 'db upgrade' and 'db populate' commands. * NAME Project name. * OBSERVATION_CONFIGURATION General and Observation type specific configuration. Type specific configuration is used if Observation is not specifying its own. \"\"\" import os from illuminate import __version__ CONCURRENCY = { \"adapters\" : 2 , \"exporters\" : 8 , \"observations\" : 8 , } DB = { \"main\" : { \"host\" : \"localhost\" , \"name\" : \"tutorial\" , \"pass\" : os . environ . get ( \"ILLUMINATE_MAIN_DB_PASSWORD\" ), \"port\" : \"5432\" , \"user\" : \"illuminate\" , \"type\" : \"postgresql\" , }, \"measurements\" : { \"host\" : \"localhost\" , \"name\" : \"tutorial\" , \"pass\" : os . environ . get ( \"ILLUMINATE_MEASUREMENTS_DB_PASSWORD\" ), \"port\" : \"8086\" , \"user\" : \"illuminate\" , \"type\" : \"influxdb\" , }, } MODELS = [ \"models.example.ModelExample\" , ] NAME = \"tutorial\" OBSERVATION_CONFIGURATION = { \"delay\" : 0.1 , \"http\" : { \"auth_username\" : None , \"auth_password\" : None , \"connect_timeout\" : 10.0 , \"body\" : None , \"headers\" : None , \"method\" : \"GET\" , \"request_timeout\" : 10.0 , \"user_agent\" : f \"Illuminate-bot/ { __version__ } \" , \"validate_cert\" : False , }, \"splash\" : { \"body\" : \"\" , \"host\" : \"localhost\" , \"method\" : \"GET\" , \"port\" : 8050 , \"protocol\" : \"http\" , \"render\" : \"html\" , \"timeout\" : 30 , } } Environment Environment for a development purposes is provided by docker-compose.yaml file. It will spin up postgres database and pgadmin containers to monitor your flow on your localhost. NOTE : As additional Observations and Exporters are added, this file will grow as well. version : '3.8' services : influxdb : image : influxdb:1.8 container_name : influxdb restart : always environment : - INFLUXDB_ADMIN_USER=illuminate - INFLUXDB_ADMIN_PASSWORD=$ILLUMINATE_MEASUREMENTS_DB_PASSWORD - INFLUXDB_DB=tutorial - INFLUXDB_HTTP_AUTH_ENABLED=true ports : - '8086:8086' volumes : - influxdb:/var/lib/influxdb pg : container_name : pg image : postgres:latest restart : always environment : - POSTGRES_USER=illuminate - POSTGRES_PASSWORD=$ILLUMINATE_MAIN_DB_PASSWORD - POSTGRES_DB=tutorial ports : - '5432:5432' volumes : - postgres:/var/lib/postgresql/data splash : container_name : splash image : scrapinghub/splash restart : always ports : - \"8050:8050\" volumes : grafana : driver : local influxdb : driver : local postgres : driver : local","title":"Structure"},{"location":"structure/#observers","text":"observers/ package is a place where you write your ETL configuration classes. Once illuminate observe start command is issued, all classes found in the package which name starts with the word \"Observer\" will be added into context and initialized. from __future__ import annotations from collections.abc import AsyncGenerator , Generator from typing import Optional , Union from urllib.parse import urldefrag from urllib.parse import urljoin from bs4 import BeautifulSoup from illuminate.manager import Manager from illuminate.observation import HTTPObservation from illuminate.observer import Observer from tornado.httpclient import HTTPResponse from exporters.example import ExporterInfluxDBExample from exporters.example import ExporterSQLExample from findings.example import FindingExample def _create_soup ( response : HTTPResponse ) -> BeautifulSoup : html = response . body . decode ( errors = \"ignore\" ) soup = BeautifulSoup ( html , \"html.parser\" ) return soup def _extract_hrefs ( soup : BeautifulSoup , url : str ) -> Generator [ str , None ]: links = soup . find_all ( \"a\" ) for link in links : _url = link . get ( \"href\" ) if _url : yield urljoin ( url , urldefrag ( _url )[ 0 ]) class ObserverExample ( Observer ): \"\"\" Observer is ETL configuration class. It represents entry point, and it defines the flow with observe, and any additional method. Once initialized by the framework, it will fill an observation queue with objects from Observer's initial_observation collection, starting the whole process. Note: Multiple Observers can exist in the same project. \"\"\" ALLOWED : Union [ list [ str ], tuple [ str ]] = ( \"https://webscraper.io/\" ,) \"\"\" Collection of strings evaluated against URL to determent if URL is allowed to be observed. If empty, no Observation wide restrictions are forced. \"\"\" LABELS : dict = { \"tag\" : \"example\" } \"\"\"Observer's labels.\"\"\" NAME : str = \"example\" \"\"\"Observer's name.\"\"\" def __init__ ( self , manager : Optional [ Manager ] = None ): \"\"\" Collection initial_observations is de facto entry point. It must contain Observation objects initialized with URL, allowed list of strings and callback method. If Observation's URL starts with element in allowed collection, it will be performed. Otherwise, it is rejected. Manager's instance (object that is running whole process) is passed as an argument when initializing Observers. This allows Observer object to interact with Manager object attributes, like database sessions or queues for advanced ETL flows, by simply asking for self.manager.sessions[\"postgresql\"][\"main\"] to acquire async database session defined in tutorial/settings.py. \"\"\" super () . __init__ ( manager ) self . initial_observations = [ HTTPObservation ( \"https://webscraper.io/\" , allowed = self . ALLOWED , callback = self . observe , ), ] async def observe ( self , response : HTTPResponse , * args , ** kwargs ) -> AsyncGenerator [ Union [ ExporterInfluxDBExample , ExporterSQLExample , FindingExample , HTTPObservation , ], None , ]: \"\"\" ETL flow is regulated by a yielded object type of Observation's callback method. Each object type corresponds to ETL stage: * Observation -> Extract * Finding -> Transform * Exporter -> Load In the example below, initial HTTPObservation returned Tornado's HTTP response object that was used to extract all hrefs from HTML. These hrefs will be used as URLs for new HTTPObservations, using the same observe method as a callback and same allowed collection. Finally, Finding object is yielded, representing a desired data. This flow, with everything set, represents a simple web scraper that will visit every page found on a domain, and take page's title and URL as desired data. Tip: If there is no need for some further data enrichment or manipulation, yield Exporter object instead of Finding object. For reference check tutorial/adapters/example.py. Note: Illuminate takes care of tracking what resources were already requested, avoiding duplication. Resource check pool is shared between Observers, avoiding overlapping. \"\"\" soup = _create_soup ( response ) hrefs = _extract_hrefs ( soup , response . effective_url ) for href in hrefs : yield HTTPObservation ( href , allowed = self . ALLOWED , callback = self . observe , ) yield FindingExample ( response . request_time , soup . title . text , response . effective_url )","title":"Observers"},{"location":"structure/#observer-vs-observation","text":"Observer is ETL configuration class. It introduces Observation objects, in this case HTTPObservation objects, through initial_observations , to a framework. It also should be used (not forced, but suggested) to contain all callback methods used by Observation objects. Observation class is a type of source that will be read. Once the data is pulled, it will provide a response object to a callback function that will asynchronously generate additional object related to ETL flow, using Illuminate ETL Mapping Classes. NOTE : You can register any async generator as HTTPObservation.callback . For simplicity, we will use ObserverExample.observe method.","title":"Observer vs Observation"},{"location":"structure/#etl-mapping-classes","text":"Each stage in ETL flow is represented by a class from Illuminate framework. Extract is represented with Observation Transform is represented with Adapter Load is represented with Exporter If a response object from initial Observation is just a step before the data you want to export, yield new Observation with same or different callback, allowing you to construct a complex set of rules. If a response object holds the data you want to adapt, yield Finding object. It will be picked up by Adapter instances that will perform adapt method with Finding object passed as argument if the condition is met. If a response object is something that requires minimal transformation, or it could be used raw, you can yield Exporter object and skip complex adaptation.","title":"ETL Mapping Classes"},{"location":"structure/#findings","text":"findings/ package is a place where you write your data classes. This class is meant to be picked up by a framework and passed to Adapter instance, to perform actual adaptation up on data, and yield Exporter or Observation objects. It can only be yielded by Observation object's callback , in our example project, it will be yield by ExampleObserver.observe method. from dataclasses import dataclass from dataclasses import field from illuminate.observer import Finding @dataclass ( frozen = True , order = True ) class FindingExample ( Finding ): \"\"\" Finding is a data class, meant to hold raw data extracted by Observation's callback. Finding will be passed to Adapter object's adapt method if it is subscribed to Adapter. Check tutorial/adapters/example.py to learn more about subscription. \"\"\" load_time : float = field () title : str = field () url : str = field ()","title":"Findings"},{"location":"structure/#model","text":"models/ package is a place where you write your database model classes. Models are used by SQLExporter in our example and are recommended method of writing and reading data from SQL database. NOTE : SQLObservation class is not yet introduced to the framework. from sqlalchemy import Column , Float , Integer , String from models import Base class ModelExample ( Base ): \"\"\" SQLAlchemy model used by SQLExporter object. For more information about SQLExporter class check tutorial/exporters/example.py. \"\"\" __tablename__ = \"tutorial\" id : int = Column ( Integer , primary_key = True ) load_time : float = Column ( Float ) title : str = Column ( String ) url : str = Column ( String ) def __repr__ ( self ): \"\"\"ModelExample's __repr__ method.\"\"\" return ( f 'ModelExample(load_time= { self . load_time } ,' f 'title=\" { self . title } \",url=\" { self . url } \")' )","title":"Model"},{"location":"structure/#adapter","text":"adapters/ package is a place where you write your transformation classes. Once illuminate observe start command is issued, all classes found in the package which name starts with the word \"Adapter\" will be added into context and initialized. Once the framework gets Finding object from a queue, it will check if object is \"subscribed\" to Adapter . If object is subscribed, the framework will pass it to adapt method that will yield Exporter or Observation objects. Method adapt is where you implement your adaptation rules. In the following example, method adapt is just used to create a model instance to be passed to SQLExpoter instance, yet to be saved later into the database. Each Adapter object must contain a tuple of Finding classes, called subscribers that will be passed to adapt method. Others will be rejected by a framework. Since there could be multiple Adapter classes with various implementation of adapt method, if Finding is subscribed to multiple Adapters , priority attribute will determent which adapt method should be called first. NOTE : Method adapt can't yield Findings . from __future__ import annotations from collections.abc import AsyncGenerator from typing import Type , Union from illuminate.adapter import Adapter from illuminate.observation import FileObservation from illuminate.observation import HTTPObservation from illuminate.observation import SQLObservation from illuminate.observation import SplashObservation from illuminate.observer import Finding from exporters.example import ExporterInfluxDBExample from exporters.example import ExporterSQLExample from findings.example import FindingExample from models.example import ModelExample class AdapterExample ( Adapter ): \"\"\" Adapter class is responsible for turning Finding objects into Exporter or Observation objects, and yielding them when adapt method is called. It is also designated to be a place where any additional enrichment of data should be performed, calling external services with some async library. If additional data can be used to construct URL, additional Observations can be yielded. For more information how to yield Observation object, check tutorial/observers/example.py. Attribute subscribers is a collection of Finding classes that will be processed by Adapter. If Finding is subscribed to two or more Adapters, priority in adaptation will be give to Adapter with higher priority score. Manager's instance (object that is running whole process) is passed as an argument when initializing Adapters. This allows Adapter object to interact with Manager object attributes, like database sessions or queues for advanced ETL flows, by simply asking for self.manager.sessions[\"postgresql\"][\"main\"] to acquire async database session defined in tutorial/settings.py. Note: Method adapt can not yield Findings. \"\"\" priority : int = 10 subscribers : tuple [ Type [ Finding ]] = ( FindingExample ,) async def adapt ( self , finding : FindingExample , * args , ** kwargs ) -> AsyncGenerator [ Union [ ExporterInfluxDBExample , ExporterSQLExample , FileObservation , HTTPObservation , SQLObservation , SplashObservation , ], None , ]: yield ExporterSQLExample ( models = [ ModelExample ( load_time = finding . load_time , title = finding . title , url = finding . url ) ] ) yield ExporterInfluxDBExample ( points = { \"measurement\" : \"tutorial\" , \"tags\" : { \"url\" : finding . url , \"title\" : finding . title }, \"fields\" : { \"load_time\" : finding . load_time }, } )","title":"Adapter"},{"location":"structure/#exporter","text":"exporters/ package is a place where you write your dump classes. from __future__ import annotations from typing import Iterable , Union from illuminate.exporter import InfluxDBExporter from illuminate.exporter import SQLExporter from pandas import DataFrame from models.example import ModelExample class ExporterInfluxDBExample ( InfluxDBExporter ): \"\"\" InfluxDBExporter class will write points to database using session. Points are passed at initialization, while database session is found by name attribute in the pool of existing sessions. Name must co-respond to DB section in tutorial/settings.py. For more information how to initialize InfluxDBExporter class, check tutorial/adapters/example.py \"\"\" name : str = \"measurements\" def __init__ ( self , points : Union [ Union [ DataFrame , dict , str , bytes ], Iterable [ Union [ DataFrame , dict , str , bytes ]], ], ): super () . __init__ ( points ) class ExporterSQLExample ( SQLExporter ): \"\"\" SQLExporter class will commit models to database using session. Models are passed at initialization, while database session is found by name attribute in the pool of existing sessions. Name must co-respond to DB section in tutorial/settings.py. For more information how to initialize SQLExporter class, check tutorial/adapters/example.py \"\"\" name : str = \"main\" def __init__ ( self , models : Union [ list [ ModelExample ], tuple [ ModelExample ]]): super () . __init__ ( models ) In our example, everything is set for Exporter object to fetch a database connection from the framework and use it to facilitate dump to the destination. Since we are writing to SQL database, we will import SQLExporter to inherit from in ExporterExample class.","title":"Exporter"},{"location":"structure/#migrations","text":"migrations/ package contains files needed by Alembic to perform database operations. It contains versions directory where migration scripts are held, providing Illuminate with the ability to administer its own databases out of the box. Usually, the content of this directory is not a user's concern.","title":"Migrations"},{"location":"structure/#fixtures","text":"Directory fixtures/ holds json files that contain data needed in ETL flow beforehand. This data is injected into the database with illuminate manage database populate cli command. Each object in a list represents a table/model. Key name represents table/model name and data is a list of rows to be inserted with CLI command. [ { \"name\" : \"tutorial\" , \"data\" : [ { \"load_time\" : \"1.0\" , \"url\" : \"https://webscraper.io/\" , \"title\" : \"Web Scraper - The #1 web scraping extension\" }, { \"load_time\" : \"1.0\" , \"url\" : \"https://webscraper.io/tutorials\" , \"title\" : \"Web Scraper Tutorials\" } ] } ]","title":"Fixtures"},{"location":"structure/#settings","text":"Module settings.py contains all configuration needed to run ETL process. \"\"\" This file represents project tutorial's settings. It will be imported by a framework and used to configure run. The sections are as following: * CONCURRENCY Number of workers per queue type. I/O heavy queues can have more workers assigned to them to exploit longer wait times. * DB Database related data used by SQLAlchemy to acquire sessions. Sessions are obtained at the start of the ETL process and can be accessed by instantiating Manager class and access sessions attribute. * MODELS List of SQLAlchemy models affected by illuminate cli when invoking 'db revision', 'db upgrade' and 'db populate' commands. * NAME Project name. * OBSERVATION_CONFIGURATION General and Observation type specific configuration. Type specific configuration is used if Observation is not specifying its own. \"\"\" import os from illuminate import __version__ CONCURRENCY = { \"adapters\" : 2 , \"exporters\" : 8 , \"observations\" : 8 , } DB = { \"main\" : { \"host\" : \"localhost\" , \"name\" : \"tutorial\" , \"pass\" : os . environ . get ( \"ILLUMINATE_MAIN_DB_PASSWORD\" ), \"port\" : \"5432\" , \"user\" : \"illuminate\" , \"type\" : \"postgresql\" , }, \"measurements\" : { \"host\" : \"localhost\" , \"name\" : \"tutorial\" , \"pass\" : os . environ . get ( \"ILLUMINATE_MEASUREMENTS_DB_PASSWORD\" ), \"port\" : \"8086\" , \"user\" : \"illuminate\" , \"type\" : \"influxdb\" , }, } MODELS = [ \"models.example.ModelExample\" , ] NAME = \"tutorial\" OBSERVATION_CONFIGURATION = { \"delay\" : 0.1 , \"http\" : { \"auth_username\" : None , \"auth_password\" : None , \"connect_timeout\" : 10.0 , \"body\" : None , \"headers\" : None , \"method\" : \"GET\" , \"request_timeout\" : 10.0 , \"user_agent\" : f \"Illuminate-bot/ { __version__ } \" , \"validate_cert\" : False , }, \"splash\" : { \"body\" : \"\" , \"host\" : \"localhost\" , \"method\" : \"GET\" , \"port\" : 8050 , \"protocol\" : \"http\" , \"render\" : \"html\" , \"timeout\" : 30 , } }","title":"Settings"},{"location":"structure/#environment","text":"Environment for a development purposes is provided by docker-compose.yaml file. It will spin up postgres database and pgadmin containers to monitor your flow on your localhost. NOTE : As additional Observations and Exporters are added, this file will grow as well. version : '3.8' services : influxdb : image : influxdb:1.8 container_name : influxdb restart : always environment : - INFLUXDB_ADMIN_USER=illuminate - INFLUXDB_ADMIN_PASSWORD=$ILLUMINATE_MEASUREMENTS_DB_PASSWORD - INFLUXDB_DB=tutorial - INFLUXDB_HTTP_AUTH_ENABLED=true ports : - '8086:8086' volumes : - influxdb:/var/lib/influxdb pg : container_name : pg image : postgres:latest restart : always environment : - POSTGRES_USER=illuminate - POSTGRES_PASSWORD=$ILLUMINATE_MAIN_DB_PASSWORD - POSTGRES_DB=tutorial ports : - '5432:5432' volumes : - postgres:/var/lib/postgresql/data splash : container_name : splash image : scrapinghub/splash restart : always ports : - \"8050:8050\" volumes : grafana : driver : local influxdb : driver : local postgres : driver : local","title":"Environment"},{"location":"support/","text":"illuminate.observation.observation.Observation ( IObservation ) Observation class, reads data from the source. Class must be inherited and method observe must be implemented in a child class. Source code in illuminate/observation/observation.py class Observation ( IObservation ): \"\"\" Observation class, reads data from the source. Class must be inherited and method observe must be implemented in a child class. \"\"\" def __hash__ ( self ): \"\"\" Observation object hash value. :return: None :raises BasicObservationException: \"\"\" raise BasicObservationException ( \"Property hash must be implemented in child class\" ) def __init__ ( self , url : Any , xcom : Optional [ Any ] = None ): \"\"\" Observation's __init__ method. :param url: Data's URL :param xcom: Cross communication object \"\"\" self . url = url self . xcom = xcom async def observe ( self , * args , ** kwargs ): \"\"\" Reads data from the source. Must be implemented in a child class. :return: None :raises BasicObservationException: \"\"\" raise BasicObservationException ( \"Method observe must be implemented in child class\" ) __hash__ ( self ) special Observation object hash value. :return: None :raises BasicObservationException: Source code in illuminate/observation/observation.py def __hash__ ( self ): \"\"\" Observation object hash value. :return: None :raises BasicObservationException: \"\"\" raise BasicObservationException ( \"Property hash must be implemented in child class\" ) __init__ ( self , url : Any , xcom : Optional [ Any ] = None ) special Observation's init method. :param url: Data's URL :param xcom: Cross communication object Source code in illuminate/observation/observation.py def __init__ ( self , url : Any , xcom : Optional [ Any ] = None ): \"\"\" Observation's __init__ method. :param url: Data's URL :param xcom: Cross communication object \"\"\" self . url = url self . xcom = xcom observe ( self , * args , ** kwargs ) async Reads data from the source. Must be implemented in a child class. :return: None :raises BasicObservationException: Source code in illuminate/observation/observation.py async def observe ( self , * args , ** kwargs ): \"\"\" Reads data from the source. Must be implemented in a child class. :return: None :raises BasicObservationException: \"\"\" raise BasicObservationException ( \"Method observe must be implemented in child class\" ) illuminate.observation.file.FileObservation ( Observation ) FileObservation class, reads file content asynchronously. Inherits Observation class and implements observe method. Source code in illuminate/observation/file.py class FileObservation ( Observation ): \"\"\" FileObservation class, reads file content asynchronously. Inherits Observation class and implements observe method. \"\"\" def __hash__ ( self ) -> int : \"\"\" FileObservation object hash value. :return: int \"\"\" return hash ( self . url ) def __init__ ( self , url : str , / , callback : Callable [[ FileIOWrapperBase , tuple , dict ], Result ], xcom : Optional [ Any ] = None , * args , ** kwargs , ): \"\"\" FileObservation's __init__ method. :param url: File path :param callback: Async function/method that manipulates FileIOWrapperBase object and returns Result :param xcom: Cross communication object \"\"\" super () . __init__ ( url , xcom = xcom ) self . _callback = callback @asynccontextmanager async def observe ( self , * args , ** kwargs ) -> AsyncIterator [ Union [ None , Result ]]: \"\"\" Opens IO file stream asynchronously, pass stream object to a callback and returns None or Result as a context manager. :return: AsyncIterator with None or Result \"\"\" _file = None _items = None async with AsyncExitStack () as stack : try : _file = await stack . enter_async_context ( async_open ( self . url , \"r\" ) ) logger . info ( f \" { self } .observe() -> { _file } \" ) _items = self . _callback ( _file , * args , ** kwargs ) except Exception as exception : logger . warning ( f \" { self } .observe() -> { exception } \" ) finally : yield _items if _file : await _file . close () def __repr__ ( self ): \"\"\" FileObservation's __repr__ method. :return: String representation of an instance \"\"\" return f 'FileObservation(\" { self . url } \",callback=\" { self . _callback } \")' __hash__ ( self ) -> int special FileObservation object hash value. :return: int Source code in illuminate/observation/file.py def __hash__ ( self ) -> int : \"\"\" FileObservation object hash value. :return: int \"\"\" return hash ( self . url ) __init__ ( / , self , url : str , callback : Callable [[ FileIOWrapperBase , tuple , dict ], Result ], xcom : Optional [ Any ] = None , * args , ** kwargs ) special FileObservation's init method. :param url: File path :param callback: Async function/method that manipulates FileIOWrapperBase object and returns Result :param xcom: Cross communication object Source code in illuminate/observation/file.py def __init__ ( self , url : str , / , callback : Callable [[ FileIOWrapperBase , tuple , dict ], Result ], xcom : Optional [ Any ] = None , * args , ** kwargs , ): \"\"\" FileObservation's __init__ method. :param url: File path :param callback: Async function/method that manipulates FileIOWrapperBase object and returns Result :param xcom: Cross communication object \"\"\" super () . __init__ ( url , xcom = xcom ) self . _callback = callback __repr__ ( self ) special FileObservation's repr method. :return: String representation of an instance Source code in illuminate/observation/file.py def __repr__ ( self ): \"\"\" FileObservation's __repr__ method. :return: String representation of an instance \"\"\" return f 'FileObservation(\" { self . url } \",callback=\" { self . _callback } \")' observe ( self , * args , ** kwargs ) -> AsyncIterator [ Union [ None , Result ]] Opens IO file stream asynchronously, pass stream object to a callback and returns None or Result as a context manager. :return: AsyncIterator with None or Result Source code in illuminate/observation/file.py @asynccontextmanager async def observe ( self , * args , ** kwargs ) -> AsyncIterator [ Union [ None , Result ]]: \"\"\" Opens IO file stream asynchronously, pass stream object to a callback and returns None or Result as a context manager. :return: AsyncIterator with None or Result \"\"\" _file = None _items = None async with AsyncExitStack () as stack : try : _file = await stack . enter_async_context ( async_open ( self . url , \"r\" ) ) logger . info ( f \" { self } .observe() -> { _file } \" ) _items = self . _callback ( _file , * args , ** kwargs ) except Exception as exception : logger . warning ( f \" { self } .observe() -> { exception } \" ) finally : yield _items if _file : await _file . close () illuminate.observation.http.HTTPObservation ( Observation ) HTTPObservation class, reads data from HTTP server asynchronously. Inherits Observation class and implements observe method. Source code in illuminate/observation/http.py class HTTPObservation ( Observation ): \"\"\" HTTPObservation class, reads data from HTTP server asynchronously. Inherits Observation class and implements observe method. \"\"\" def __hash__ ( self ) -> int : \"\"\" HTTPObservation object hash value. :return: int \"\"\" body = self . configuration . get ( \"body\" ) method = self . configuration . get ( \"method\" ) return hash ( f \" { method } | { self . url } |: { body } \" ) def __init__ ( self , url : str , / , allowed : Union [ list [ str ], tuple [ str ]], callback : Callable [[ HTTPResponse , tuple , dict ], Result ], xcom : Optional [ Any ] = None , * args , ** kwargs , ): \"\"\" HTTPObservation's __init__ method. :param url: Data's HTTP URL :param allowed: Collection of strings evaluated against self.url to determent if URL is allowed :param callback: Async function/method that manipulates HTTPResponse object and returns Result. :param xcom: Cross communication object \"\"\" super () . __init__ ( url , xcom = xcom ) self . _allowed = allowed self . _callback = callback self . configuration = kwargs @property def allowed ( self ) -> bool : \"\"\" Checks if HTTP URL is allowed to be requested. :return: bool \"\"\" for allowed in self . _allowed : if self . url . startswith ( allowed ): return True return False async def observe ( self , * args , ** kwargs ) -> Union [ None , Result ]: \"\"\" Requests data from HTTP server, passes response object to a callback and returns None or Result. :return: None or Result \"\"\" try : response = await httpclient . AsyncHTTPClient () . fetch ( self . url , ** self . configuration ) logger . info ( f \" { self } .observe() -> { response } \" ) return self . _callback ( response , * args , ** kwargs ) except Exception as exception : logger . warning ( f \" { self } .observe() -> { exception } \" ) return None def __repr__ ( self ): \"\"\" HTTPObservation's __repr__ method. :return: String representation of an instance \"\"\" return f 'HTTPObservation(\" { self . url } \",callback=\" { self . _callback } \")' allowed : bool property readonly Checks if HTTP URL is allowed to be requested. :return: bool __hash__ ( self ) -> int special HTTPObservation object hash value. :return: int Source code in illuminate/observation/http.py def __hash__ ( self ) -> int : \"\"\" HTTPObservation object hash value. :return: int \"\"\" body = self . configuration . get ( \"body\" ) method = self . configuration . get ( \"method\" ) return hash ( f \" { method } | { self . url } |: { body } \" ) __init__ ( / , self , url : str , allowed : Union [ list [ str ], tuple [ str ]], callback : Callable [[ HTTPResponse , tuple , dict ], Result ], xcom : Optional [ Any ] = None , * args , ** kwargs ) special HTTPObservation's init method. :param url: Data's HTTP URL :param allowed: Collection of strings evaluated against self.url to determent if URL is allowed :param callback: Async function/method that manipulates HTTPResponse object and returns Result. :param xcom: Cross communication object Source code in illuminate/observation/http.py def __init__ ( self , url : str , / , allowed : Union [ list [ str ], tuple [ str ]], callback : Callable [[ HTTPResponse , tuple , dict ], Result ], xcom : Optional [ Any ] = None , * args , ** kwargs , ): \"\"\" HTTPObservation's __init__ method. :param url: Data's HTTP URL :param allowed: Collection of strings evaluated against self.url to determent if URL is allowed :param callback: Async function/method that manipulates HTTPResponse object and returns Result. :param xcom: Cross communication object \"\"\" super () . __init__ ( url , xcom = xcom ) self . _allowed = allowed self . _callback = callback self . configuration = kwargs __repr__ ( self ) special HTTPObservation's repr method. :return: String representation of an instance Source code in illuminate/observation/http.py def __repr__ ( self ): \"\"\" HTTPObservation's __repr__ method. :return: String representation of an instance \"\"\" return f 'HTTPObservation(\" { self . url } \",callback=\" { self . _callback } \")' observe ( self , * args , ** kwargs ) -> Union [ None , Result ] async Requests data from HTTP server, passes response object to a callback and returns None or Result. :return: None or Result Source code in illuminate/observation/http.py async def observe ( self , * args , ** kwargs ) -> Union [ None , Result ]: \"\"\" Requests data from HTTP server, passes response object to a callback and returns None or Result. :return: None or Result \"\"\" try : response = await httpclient . AsyncHTTPClient () . fetch ( self . url , ** self . configuration ) logger . info ( f \" { self } .observe() -> { response } \" ) return self . _callback ( response , * args , ** kwargs ) except Exception as exception : logger . warning ( f \" { self } .observe() -> { exception } \" ) return None illuminate.observation.sql.SQLObservation ( Observation ) SQLObservation class, reads data from database asynchronously. Inherits Observation class and implements observe method. Source code in illuminate/observation/sql.py class SQLObservation ( Observation ): \"\"\" SQLObservation class, reads data from database asynchronously. Inherits Observation class and implements observe method. \"\"\" def __hash__ ( self ) -> int : \"\"\" SQLObservation object hash value. :return: int \"\"\" query = str ( self . query ) return hash ( f \" { self . url } |: { query } \" ) def __init__ ( self , query : Union [ Select , TextClause ], url : str , / , callback : Callable [[ AlchemyResult , tuple , dict ], Result ], xcom : Optional [ Any ] = None , * args , ** kwargs , ): \"\"\" SQLObservation's __init__ method. :param query: SQLAlchemy query object. :param url: Database name in project settings. :param callback: Async function/method that manipulates AlchemyResult object and returns Result. :param xcom: Cross communication object \"\"\" super () . __init__ ( url , xcom = xcom ) self . _callback = callback self . query = query async def observe ( self , session : Type [ AsyncSession ], * args , ** kwargs ) -> Union [ None , Result ]: \"\"\" Reads data from database, passes response object to a callback and returns None or Result. :return: None or Result \"\"\" try : async with session () as session : # type: ignore async with session . begin (): # type: ignore query = self . query response = await session . execute ( query ) # type: ignore logger . info ( f ' { self } .observe(session=\" { session } \")' ) return self . _callback ( response , * args , ** kwargs ) except Exception as exception : logger . warning ( f \" { self } .observe() -> { exception } \" ) return None def __repr__ ( self ): \"\"\" SQLObservation's __repr__ method. :return: String representation of an instance \"\"\" return ( f 'SQLObservation(\" { self . query } \",\" { self . url } \",' f 'callback=\" { self . _callback } \")' ) __hash__ ( self ) -> int special SQLObservation object hash value. :return: int Source code in illuminate/observation/sql.py def __hash__ ( self ) -> int : \"\"\" SQLObservation object hash value. :return: int \"\"\" query = str ( self . query ) return hash ( f \" { self . url } |: { query } \" ) __init__ ( / , self , query : Union [ Select , TextClause ], url : str , callback : Callable [[ AlchemyResult , tuple , dict ], Result ], xcom : Optional [ Any ] = None , * args , ** kwargs ) special SQLObservation's init method. :param query: SQLAlchemy query object. :param url: Database name in project settings. :param callback: Async function/method that manipulates AlchemyResult object and returns Result. :param xcom: Cross communication object Source code in illuminate/observation/sql.py def __init__ ( self , query : Union [ Select , TextClause ], url : str , / , callback : Callable [[ AlchemyResult , tuple , dict ], Result ], xcom : Optional [ Any ] = None , * args , ** kwargs , ): \"\"\" SQLObservation's __init__ method. :param query: SQLAlchemy query object. :param url: Database name in project settings. :param callback: Async function/method that manipulates AlchemyResult object and returns Result. :param xcom: Cross communication object \"\"\" super () . __init__ ( url , xcom = xcom ) self . _callback = callback self . query = query __repr__ ( self ) special SQLObservation's repr method. :return: String representation of an instance Source code in illuminate/observation/sql.py def __repr__ ( self ): \"\"\" SQLObservation's __repr__ method. :return: String representation of an instance \"\"\" return ( f 'SQLObservation(\" { self . query } \",\" { self . url } \",' f 'callback=\" { self . _callback } \")' ) observe ( self , session : Type [ AsyncSession ], * args , ** kwargs ) -> Union [ None , Result ] async Reads data from database, passes response object to a callback and returns None or Result. :return: None or Result Source code in illuminate/observation/sql.py async def observe ( self , session : Type [ AsyncSession ], * args , ** kwargs ) -> Union [ None , Result ]: \"\"\" Reads data from database, passes response object to a callback and returns None or Result. :return: None or Result \"\"\" try : async with session () as session : # type: ignore async with session . begin (): # type: ignore query = self . query response = await session . execute ( query ) # type: ignore logger . info ( f ' { self } .observe(session=\" { session } \")' ) return self . _callback ( response , * args , ** kwargs ) except Exception as exception : logger . warning ( f \" { self } .observe() -> { exception } \" ) return None illuminate.observation.http.SplashObservation ( HTTPObservation ) SplashObservation class, reads data from HTTP server asynchronously. Inherits HTTPObservation class and implements observe method. Constructor's kwargs are used to create Splash service URL. For full list of parameters visit https://splash.readthedocs.io/en/stable/api.html. Note: URL is passed as positional argument. It will be used as param in Splash service URL. Source code in illuminate/observation/http.py class SplashObservation ( HTTPObservation ): \"\"\" SplashObservation class, reads data from HTTP server asynchronously. Inherits HTTPObservation class and implements observe method. Constructor's kwargs are used to create Splash service URL. For full list of parameters visit https://splash.readthedocs.io/en/stable/api.html. Note: URL is passed as positional argument. It will be used as param in Splash service URL. \"\"\" def __hash__ ( self ) -> int : \"\"\" SplashObservation object hash value. :return: int \"\"\" return hash ( self . service ) @property def service ( self ): \"\"\" Constructs URL of Splash service :return: Splash URL string \"\"\" defaults : dict = { \"host\" : \"localhost\" , \"port\" : 8050 , \"protocol\" : \"http\" , \"render\" : \"html\" , } parameters = copy ( self . configuration ) for i in defaults : if i in parameters : defaults [ i ] = parameters [ i ] del parameters [ i ] parameters [ \"url\" ] = self . url endpoint = \" {protocol} :// {host} : {port} /render. {render} ?\" endpoint = endpoint . format ( ** defaults ) parameters = urllib . parse . urlencode ( parameters ) return f \" { endpoint . format ( ** defaults ) }{ parameters } \" async def observe ( self , configuration : dict , * args , ** kwargs ) -> Union [ None , Result ]: \"\"\" Requests data from HTTP server and renders response with Splash, passes response object to a callback and returns None or Result. :param configuration: HTTP configuration dict from settings.py :return: None or Result \"\"\" try : response = await httpclient . AsyncHTTPClient () . fetch ( self . service , ** configuration ) logger . info ( f \" { self } .observe() -> { response } \" ) return self . _callback ( response , * args , ** kwargs ) except Exception as exception : logger . warning ( f \" { self } .observe() -> { exception } \" ) return None def __repr__ ( self ): \"\"\" SplashObservation's __repr__ method. :return: String representation of an instance \"\"\" return f 'SplashObservation(\" { self . url } \",callback=\" { self . _callback } \")' service property readonly Constructs URL of Splash service :return: Splash URL string __hash__ ( self ) -> int special SplashObservation object hash value. :return: int Source code in illuminate/observation/http.py def __hash__ ( self ) -> int : \"\"\" SplashObservation object hash value. :return: int \"\"\" return hash ( self . service ) __repr__ ( self ) special SplashObservation's repr method. :return: String representation of an instance Source code in illuminate/observation/http.py def __repr__ ( self ): \"\"\" SplashObservation's __repr__ method. :return: String representation of an instance \"\"\" return f 'SplashObservation(\" { self . url } \",callback=\" { self . _callback } \")' observe ( self , configuration : dict , * args , ** kwargs ) -> Union [ None , Result ] async Requests data from HTTP server and renders response with Splash, passes response object to a callback and returns None or Result. :param configuration: HTTP configuration dict from settings.py :return: None or Result Source code in illuminate/observation/http.py async def observe ( self , configuration : dict , * args , ** kwargs ) -> Union [ None , Result ]: \"\"\" Requests data from HTTP server and renders response with Splash, passes response object to a callback and returns None or Result. :param configuration: HTTP configuration dict from settings.py :return: None or Result \"\"\" try : response = await httpclient . AsyncHTTPClient () . fetch ( self . service , ** configuration ) logger . info ( f \" { self } .observe() -> { response } \" ) return self . _callback ( response , * args , ** kwargs ) except Exception as exception : logger . warning ( f \" { self } .observe() -> { exception } \" ) return None illuminate.observer.finding.Finding ( IFinding ) Finding class, contains data that will be passed to Adapter object's adapt method. Source code in illuminate/observer/finding.py class Finding ( IFinding ): \"\"\" Finding class, contains data that will be passed to Adapter object's adapt method. \"\"\" illuminate.adapter.adapter.Adapter ( IAdapter ) Adapter class, generates Exporter and Observation objects using Finding instances with optional transformation. Class must be inherited and method adapt must be implemented in a child class. Source code in illuminate/adapter/adapter.py class Adapter ( IAdapter ): \"\"\" Adapter class, generates Exporter and Observation objects using Finding instances with optional transformation. Class must be inherited and method adapt must be implemented in a child class. \"\"\" priority : int \"\"\" Place in Adapter list. If two Adapters have the same Finding in subscriber tuple, one with the higher priority will call method adapt first on Finding object. \"\"\" subscribers : tuple [ Type [ Finding ]] \"\"\" Tuple of Finding class children used to determent if Adapter object should call method adapt on Finding instance. \"\"\" def __init__ ( self , manager : Optional [ Manager ] = None ): \"\"\" Adapter's __init__ method. :param manager: Manager object \"\"\" self . manager = manager async def adapt ( self , finding : Finding , * args , ** kwargs ) -> AsyncGenerator [ Union [ Exporter , Observation ], None ]: \"\"\" Generates Exporter and Observation objects. Must be implemented in a child class. It is meant to be a scope where additional transformation up on finding objects should be performed (like data enrichment from additional data source) before yielding Exporter or Observation instances. :param finding: Finding object :return: Async Exporter and Observation object generator :raises BasicAdapterException: \"\"\" raise BasicAdapterException ( \"Method adapt must be implemented in child class\" ) __init__ ( self , manager : Optional [ Manager ] = None ) special Adapter's init method. :param manager: Manager object Source code in illuminate/adapter/adapter.py def __init__ ( self , manager : Optional [ Manager ] = None ): \"\"\" Adapter's __init__ method. :param manager: Manager object \"\"\" self . manager = manager adapt ( self , finding : Finding , * args , ** kwargs ) -> AsyncGenerator [ Union [ Exporter , Observation ], None ] async Generates Exporter and Observation objects. Must be implemented in a child class. It is meant to be a scope where additional transformation up on finding objects should be performed (like data enrichment from additional data source) before yielding Exporter or Observation instances. :param finding: Finding object :return: Async Exporter and Observation object generator :raises BasicAdapterException: Source code in illuminate/adapter/adapter.py async def adapt ( self , finding : Finding , * args , ** kwargs ) -> AsyncGenerator [ Union [ Exporter , Observation ], None ]: \"\"\" Generates Exporter and Observation objects. Must be implemented in a child class. It is meant to be a scope where additional transformation up on finding objects should be performed (like data enrichment from additional data source) before yielding Exporter or Observation instances. :param finding: Finding object :return: Async Exporter and Observation object generator :raises BasicAdapterException: \"\"\" raise BasicAdapterException ( \"Method adapt must be implemented in child class\" ) illuminate.exporter.exporter.Exporter ( IExporter ) Exporter class, writes data to destination. Class must be inherited and method export must be implemented in a child class. Source code in illuminate/exporter/exporter.py class Exporter ( IExporter ): \"\"\" Exporter class, writes data to destination. Class must be inherited and method export must be implemented in a child class. \"\"\" async def export ( self , * args , ** kwargs ): \"\"\" Writes data to destination. Must be implemented in a child class. :return: None :raises BasicExporterException: \"\"\" raise BasicExporterException ( \"Method export must be implemented in child class\" ) export ( self , * args , ** kwargs ) async Writes data to destination. Must be implemented in a child class. :return: None :raises BasicExporterException: Source code in illuminate/exporter/exporter.py async def export ( self , * args , ** kwargs ): \"\"\" Writes data to destination. Must be implemented in a child class. :return: None :raises BasicExporterException: \"\"\" raise BasicExporterException ( \"Method export must be implemented in child class\" ) illuminate.exporter.influxdb.InfluxDBExporter ( Exporter ) InfluxDBExporter class, writes data to InfluxDB database asynchronously. Inherits Exporter class and implements export method. Each InfluxDBExporter object is responsible for a single transaction with a single database. Attribute name is used to acquire database session object from Manager's sessions attribute. Constructor kwargs will be passed to client write method. For more information on write method, visit: https://aioinflux.readthedocs.io/en/stable/api.html Supported write data objects: - DataFrame with DatetimeIndex - Dict containing the keys: measurement, time, tags, fields - String (str or bytes) properly formatted in InfluxDB\u2019s line protocol - An iterable of one of the above Source code in illuminate/exporter/influxdb.py class InfluxDBExporter ( Exporter ): \"\"\" InfluxDBExporter class, writes data to InfluxDB database asynchronously. Inherits Exporter class and implements export method. Each InfluxDBExporter object is responsible for a single transaction with a single database. Attribute name is used to acquire database session object from Manager's sessions attribute. Constructor kwargs will be passed to client write method. For more information on write method, visit: https://aioinflux.readthedocs.io/en/stable/api.html Supported write data objects: - DataFrame with DatetimeIndex - Dict containing the keys: measurement, time, tags, fields - String (str or bytes) properly formatted in InfluxDB\u2019s line protocol - An iterable of one of the above \"\"\" name : str \"\"\" InfluxDB database name selector used to get database session object from Manager.sessions attribute. \"\"\" def __init__ ( self , points : Union [ Union [ DataFrame , dict , str , bytes ], Iterable [ Union [ DataFrame , dict , str , bytes ]], ], * args , ** kwargs , ): \"\"\" InfluxDBExporter's __init__ method. :param points: Supported data objects \"\"\" self . params = kwargs self . points = points async def export ( self , session : InfluxDBClient , * args , ** kwargs ) -> None : \"\"\" Writes data to Influxdb asynchronously. :param session: InfluxDBClient object :return: None :raises BasicExporterException: \"\"\" try : await session . write ( self . points , ** self . params ) except Exception as exception : logger . warning ( f ' { self } .export(session=\" { session } \") -> { exception } ' ) raise BasicExporterException logger . success ( f ' { self } .export(session=\" { session } \")' ) def __repr__ ( self ): \"\"\" InfluxDBExporter's __repr__ method. :return: String representation of an instance \"\"\" return f \"InfluxDBExporter(points= { self . points } )\" __init__ ( self , points : Union [ Union [ DataFrame , dict , str , bytes ], Iterable [ Union [ DataFrame , dict , str , bytes ]]], * args , ** kwargs ) special InfluxDBExporter's init method. :param points: Supported data objects Source code in illuminate/exporter/influxdb.py def __init__ ( self , points : Union [ Union [ DataFrame , dict , str , bytes ], Iterable [ Union [ DataFrame , dict , str , bytes ]], ], * args , ** kwargs , ): \"\"\" InfluxDBExporter's __init__ method. :param points: Supported data objects \"\"\" self . params = kwargs self . points = points __repr__ ( self ) special InfluxDBExporter's repr method. :return: String representation of an instance Source code in illuminate/exporter/influxdb.py def __repr__ ( self ): \"\"\" InfluxDBExporter's __repr__ method. :return: String representation of an instance \"\"\" return f \"InfluxDBExporter(points= { self . points } )\" export ( self , session : InfluxDBClient , * args , ** kwargs ) -> None async Writes data to Influxdb asynchronously. :param session: InfluxDBClient object :return: None :raises BasicExporterException: Source code in illuminate/exporter/influxdb.py async def export ( self , session : InfluxDBClient , * args , ** kwargs ) -> None : \"\"\" Writes data to Influxdb asynchronously. :param session: InfluxDBClient object :return: None :raises BasicExporterException: \"\"\" try : await session . write ( self . points , ** self . params ) except Exception as exception : logger . warning ( f ' { self } .export(session=\" { session } \") -> { exception } ' ) raise BasicExporterException logger . success ( f ' { self } .export(session=\" { session } \")' ) illuminate.exporter.sql.SQLExporter ( Exporter ) SQLExporter class, writes data to SQL database asynchronously. Inherits Exporter class and implements export method. Each SQLExporter object is responsible for a single transaction with a single database. Attribute name is used to acquire database session object from Manager's sessions attribute. Supported dialects: - Mysql - Postgres Source code in illuminate/exporter/sql.py class SQLExporter ( Exporter ): \"\"\" SQLExporter class, writes data to SQL database asynchronously. Inherits Exporter class and implements export method. Each SQLExporter object is responsible for a single transaction with a single database. Attribute name is used to acquire database session object from Manager's sessions attribute. Supported dialects: - Mysql - Postgres \"\"\" name : str \"\"\" SQL database name selector used to get database session object from Manager.sessions attribute. \"\"\" def __init__ ( self , models : Union [ list [ M ], tuple [ M ]]): \"\"\" SQLExporter's __init__ method. :param models: SQLAlchemy model objects collection \"\"\" self . models = models async def export ( self , session : Type [ AsyncSession ], * args , ** kwargs ) -> None : \"\"\" Writes data to SQL database asynchronously. :param session: AsyncSession object :return: None :raises BasicExporterException: \"\"\" async with session () as session : # type: ignore async with session . begin (): # type: ignore session . add_all ( self . models ) # type: ignore try : await session . commit () # type: ignore except Exception as exception : logger . warning ( f ' { self } .export(session=\" { session } \") -> { exception } ' ) raise BasicExporterException logger . success ( f ' { self } .export(session=\" { session } \")' ) def __repr__ ( self ): \"\"\" SQLExporter's __repr__ method. :return: String representation of an instance \"\"\" return f \"SQLExporter(models= { self . models } )\" __init__ ( self , models : Union [ list [ M ], tuple [ M ]]) special SQLExporter's init method. :param models: SQLAlchemy model objects collection Source code in illuminate/exporter/sql.py def __init__ ( self , models : Union [ list [ M ], tuple [ M ]]): \"\"\" SQLExporter's __init__ method. :param models: SQLAlchemy model objects collection \"\"\" self . models = models __repr__ ( self ) special SQLExporter's repr method. :return: String representation of an instance Source code in illuminate/exporter/sql.py def __repr__ ( self ): \"\"\" SQLExporter's __repr__ method. :return: String representation of an instance \"\"\" return f \"SQLExporter(models= { self . models } )\" export ( self , session : Type [ AsyncSession ], * args , ** kwargs ) -> None async Writes data to SQL database asynchronously. :param session: AsyncSession object :return: None :raises BasicExporterException: Source code in illuminate/exporter/sql.py async def export ( self , session : Type [ AsyncSession ], * args , ** kwargs ) -> None : \"\"\" Writes data to SQL database asynchronously. :param session: AsyncSession object :return: None :raises BasicExporterException: \"\"\" async with session () as session : # type: ignore async with session . begin (): # type: ignore session . add_all ( self . models ) # type: ignore try : await session . commit () # type: ignore except Exception as exception : logger . warning ( f ' { self } .export(session=\" { session } \") -> { exception } ' ) raise BasicExporterException logger . success ( f ' { self } .export(session=\" { session } \")' )","title":"Support Classes"},{"location":"support/#illuminate.observation.observation.Observation","text":"Observation class, reads data from the source. Class must be inherited and method observe must be implemented in a child class. Source code in illuminate/observation/observation.py class Observation ( IObservation ): \"\"\" Observation class, reads data from the source. Class must be inherited and method observe must be implemented in a child class. \"\"\" def __hash__ ( self ): \"\"\" Observation object hash value. :return: None :raises BasicObservationException: \"\"\" raise BasicObservationException ( \"Property hash must be implemented in child class\" ) def __init__ ( self , url : Any , xcom : Optional [ Any ] = None ): \"\"\" Observation's __init__ method. :param url: Data's URL :param xcom: Cross communication object \"\"\" self . url = url self . xcom = xcom async def observe ( self , * args , ** kwargs ): \"\"\" Reads data from the source. Must be implemented in a child class. :return: None :raises BasicObservationException: \"\"\" raise BasicObservationException ( \"Method observe must be implemented in child class\" )","title":"Observation"},{"location":"support/#illuminate.observation.observation.Observation.__hash__","text":"Observation object hash value. :return: None :raises BasicObservationException: Source code in illuminate/observation/observation.py def __hash__ ( self ): \"\"\" Observation object hash value. :return: None :raises BasicObservationException: \"\"\" raise BasicObservationException ( \"Property hash must be implemented in child class\" )","title":"__hash__()"},{"location":"support/#illuminate.observation.observation.Observation.__init__","text":"Observation's init method. :param url: Data's URL :param xcom: Cross communication object Source code in illuminate/observation/observation.py def __init__ ( self , url : Any , xcom : Optional [ Any ] = None ): \"\"\" Observation's __init__ method. :param url: Data's URL :param xcom: Cross communication object \"\"\" self . url = url self . xcom = xcom","title":"__init__()"},{"location":"support/#illuminate.observation.observation.Observation.observe","text":"Reads data from the source. Must be implemented in a child class. :return: None :raises BasicObservationException: Source code in illuminate/observation/observation.py async def observe ( self , * args , ** kwargs ): \"\"\" Reads data from the source. Must be implemented in a child class. :return: None :raises BasicObservationException: \"\"\" raise BasicObservationException ( \"Method observe must be implemented in child class\" )","title":"observe()"},{"location":"support/#illuminate.observation.file.FileObservation","text":"FileObservation class, reads file content asynchronously. Inherits Observation class and implements observe method. Source code in illuminate/observation/file.py class FileObservation ( Observation ): \"\"\" FileObservation class, reads file content asynchronously. Inherits Observation class and implements observe method. \"\"\" def __hash__ ( self ) -> int : \"\"\" FileObservation object hash value. :return: int \"\"\" return hash ( self . url ) def __init__ ( self , url : str , / , callback : Callable [[ FileIOWrapperBase , tuple , dict ], Result ], xcom : Optional [ Any ] = None , * args , ** kwargs , ): \"\"\" FileObservation's __init__ method. :param url: File path :param callback: Async function/method that manipulates FileIOWrapperBase object and returns Result :param xcom: Cross communication object \"\"\" super () . __init__ ( url , xcom = xcom ) self . _callback = callback @asynccontextmanager async def observe ( self , * args , ** kwargs ) -> AsyncIterator [ Union [ None , Result ]]: \"\"\" Opens IO file stream asynchronously, pass stream object to a callback and returns None or Result as a context manager. :return: AsyncIterator with None or Result \"\"\" _file = None _items = None async with AsyncExitStack () as stack : try : _file = await stack . enter_async_context ( async_open ( self . url , \"r\" ) ) logger . info ( f \" { self } .observe() -> { _file } \" ) _items = self . _callback ( _file , * args , ** kwargs ) except Exception as exception : logger . warning ( f \" { self } .observe() -> { exception } \" ) finally : yield _items if _file : await _file . close () def __repr__ ( self ): \"\"\" FileObservation's __repr__ method. :return: String representation of an instance \"\"\" return f 'FileObservation(\" { self . url } \",callback=\" { self . _callback } \")'","title":"FileObservation"},{"location":"support/#illuminate.observation.file.FileObservation.__hash__","text":"FileObservation object hash value. :return: int Source code in illuminate/observation/file.py def __hash__ ( self ) -> int : \"\"\" FileObservation object hash value. :return: int \"\"\" return hash ( self . url )","title":"__hash__()"},{"location":"support/#illuminate.observation.file.FileObservation.__init__","text":"FileObservation's init method. :param url: File path :param callback: Async function/method that manipulates FileIOWrapperBase object and returns Result :param xcom: Cross communication object Source code in illuminate/observation/file.py def __init__ ( self , url : str , / , callback : Callable [[ FileIOWrapperBase , tuple , dict ], Result ], xcom : Optional [ Any ] = None , * args , ** kwargs , ): \"\"\" FileObservation's __init__ method. :param url: File path :param callback: Async function/method that manipulates FileIOWrapperBase object and returns Result :param xcom: Cross communication object \"\"\" super () . __init__ ( url , xcom = xcom ) self . _callback = callback","title":"__init__()"},{"location":"support/#illuminate.observation.file.FileObservation.__repr__","text":"FileObservation's repr method. :return: String representation of an instance Source code in illuminate/observation/file.py def __repr__ ( self ): \"\"\" FileObservation's __repr__ method. :return: String representation of an instance \"\"\" return f 'FileObservation(\" { self . url } \",callback=\" { self . _callback } \")'","title":"__repr__()"},{"location":"support/#illuminate.observation.file.FileObservation.observe","text":"Opens IO file stream asynchronously, pass stream object to a callback and returns None or Result as a context manager. :return: AsyncIterator with None or Result Source code in illuminate/observation/file.py @asynccontextmanager async def observe ( self , * args , ** kwargs ) -> AsyncIterator [ Union [ None , Result ]]: \"\"\" Opens IO file stream asynchronously, pass stream object to a callback and returns None or Result as a context manager. :return: AsyncIterator with None or Result \"\"\" _file = None _items = None async with AsyncExitStack () as stack : try : _file = await stack . enter_async_context ( async_open ( self . url , \"r\" ) ) logger . info ( f \" { self } .observe() -> { _file } \" ) _items = self . _callback ( _file , * args , ** kwargs ) except Exception as exception : logger . warning ( f \" { self } .observe() -> { exception } \" ) finally : yield _items if _file : await _file . close ()","title":"observe()"},{"location":"support/#illuminate.observation.http.HTTPObservation","text":"HTTPObservation class, reads data from HTTP server asynchronously. Inherits Observation class and implements observe method. Source code in illuminate/observation/http.py class HTTPObservation ( Observation ): \"\"\" HTTPObservation class, reads data from HTTP server asynchronously. Inherits Observation class and implements observe method. \"\"\" def __hash__ ( self ) -> int : \"\"\" HTTPObservation object hash value. :return: int \"\"\" body = self . configuration . get ( \"body\" ) method = self . configuration . get ( \"method\" ) return hash ( f \" { method } | { self . url } |: { body } \" ) def __init__ ( self , url : str , / , allowed : Union [ list [ str ], tuple [ str ]], callback : Callable [[ HTTPResponse , tuple , dict ], Result ], xcom : Optional [ Any ] = None , * args , ** kwargs , ): \"\"\" HTTPObservation's __init__ method. :param url: Data's HTTP URL :param allowed: Collection of strings evaluated against self.url to determent if URL is allowed :param callback: Async function/method that manipulates HTTPResponse object and returns Result. :param xcom: Cross communication object \"\"\" super () . __init__ ( url , xcom = xcom ) self . _allowed = allowed self . _callback = callback self . configuration = kwargs @property def allowed ( self ) -> bool : \"\"\" Checks if HTTP URL is allowed to be requested. :return: bool \"\"\" for allowed in self . _allowed : if self . url . startswith ( allowed ): return True return False async def observe ( self , * args , ** kwargs ) -> Union [ None , Result ]: \"\"\" Requests data from HTTP server, passes response object to a callback and returns None or Result. :return: None or Result \"\"\" try : response = await httpclient . AsyncHTTPClient () . fetch ( self . url , ** self . configuration ) logger . info ( f \" { self } .observe() -> { response } \" ) return self . _callback ( response , * args , ** kwargs ) except Exception as exception : logger . warning ( f \" { self } .observe() -> { exception } \" ) return None def __repr__ ( self ): \"\"\" HTTPObservation's __repr__ method. :return: String representation of an instance \"\"\" return f 'HTTPObservation(\" { self . url } \",callback=\" { self . _callback } \")'","title":"HTTPObservation"},{"location":"support/#illuminate.observation.http.HTTPObservation.allowed","text":"Checks if HTTP URL is allowed to be requested. :return: bool","title":"allowed"},{"location":"support/#illuminate.observation.http.HTTPObservation.__hash__","text":"HTTPObservation object hash value. :return: int Source code in illuminate/observation/http.py def __hash__ ( self ) -> int : \"\"\" HTTPObservation object hash value. :return: int \"\"\" body = self . configuration . get ( \"body\" ) method = self . configuration . get ( \"method\" ) return hash ( f \" { method } | { self . url } |: { body } \" )","title":"__hash__()"},{"location":"support/#illuminate.observation.http.HTTPObservation.__init__","text":"HTTPObservation's init method. :param url: Data's HTTP URL :param allowed: Collection of strings evaluated against self.url to determent if URL is allowed :param callback: Async function/method that manipulates HTTPResponse object and returns Result. :param xcom: Cross communication object Source code in illuminate/observation/http.py def __init__ ( self , url : str , / , allowed : Union [ list [ str ], tuple [ str ]], callback : Callable [[ HTTPResponse , tuple , dict ], Result ], xcom : Optional [ Any ] = None , * args , ** kwargs , ): \"\"\" HTTPObservation's __init__ method. :param url: Data's HTTP URL :param allowed: Collection of strings evaluated against self.url to determent if URL is allowed :param callback: Async function/method that manipulates HTTPResponse object and returns Result. :param xcom: Cross communication object \"\"\" super () . __init__ ( url , xcom = xcom ) self . _allowed = allowed self . _callback = callback self . configuration = kwargs","title":"__init__()"},{"location":"support/#illuminate.observation.http.HTTPObservation.__repr__","text":"HTTPObservation's repr method. :return: String representation of an instance Source code in illuminate/observation/http.py def __repr__ ( self ): \"\"\" HTTPObservation's __repr__ method. :return: String representation of an instance \"\"\" return f 'HTTPObservation(\" { self . url } \",callback=\" { self . _callback } \")'","title":"__repr__()"},{"location":"support/#illuminate.observation.http.HTTPObservation.observe","text":"Requests data from HTTP server, passes response object to a callback and returns None or Result. :return: None or Result Source code in illuminate/observation/http.py async def observe ( self , * args , ** kwargs ) -> Union [ None , Result ]: \"\"\" Requests data from HTTP server, passes response object to a callback and returns None or Result. :return: None or Result \"\"\" try : response = await httpclient . AsyncHTTPClient () . fetch ( self . url , ** self . configuration ) logger . info ( f \" { self } .observe() -> { response } \" ) return self . _callback ( response , * args , ** kwargs ) except Exception as exception : logger . warning ( f \" { self } .observe() -> { exception } \" ) return None","title":"observe()"},{"location":"support/#illuminate.observation.sql.SQLObservation","text":"SQLObservation class, reads data from database asynchronously. Inherits Observation class and implements observe method. Source code in illuminate/observation/sql.py class SQLObservation ( Observation ): \"\"\" SQLObservation class, reads data from database asynchronously. Inherits Observation class and implements observe method. \"\"\" def __hash__ ( self ) -> int : \"\"\" SQLObservation object hash value. :return: int \"\"\" query = str ( self . query ) return hash ( f \" { self . url } |: { query } \" ) def __init__ ( self , query : Union [ Select , TextClause ], url : str , / , callback : Callable [[ AlchemyResult , tuple , dict ], Result ], xcom : Optional [ Any ] = None , * args , ** kwargs , ): \"\"\" SQLObservation's __init__ method. :param query: SQLAlchemy query object. :param url: Database name in project settings. :param callback: Async function/method that manipulates AlchemyResult object and returns Result. :param xcom: Cross communication object \"\"\" super () . __init__ ( url , xcom = xcom ) self . _callback = callback self . query = query async def observe ( self , session : Type [ AsyncSession ], * args , ** kwargs ) -> Union [ None , Result ]: \"\"\" Reads data from database, passes response object to a callback and returns None or Result. :return: None or Result \"\"\" try : async with session () as session : # type: ignore async with session . begin (): # type: ignore query = self . query response = await session . execute ( query ) # type: ignore logger . info ( f ' { self } .observe(session=\" { session } \")' ) return self . _callback ( response , * args , ** kwargs ) except Exception as exception : logger . warning ( f \" { self } .observe() -> { exception } \" ) return None def __repr__ ( self ): \"\"\" SQLObservation's __repr__ method. :return: String representation of an instance \"\"\" return ( f 'SQLObservation(\" { self . query } \",\" { self . url } \",' f 'callback=\" { self . _callback } \")' )","title":"SQLObservation"},{"location":"support/#illuminate.observation.sql.SQLObservation.__hash__","text":"SQLObservation object hash value. :return: int Source code in illuminate/observation/sql.py def __hash__ ( self ) -> int : \"\"\" SQLObservation object hash value. :return: int \"\"\" query = str ( self . query ) return hash ( f \" { self . url } |: { query } \" )","title":"__hash__()"},{"location":"support/#illuminate.observation.sql.SQLObservation.__init__","text":"SQLObservation's init method. :param query: SQLAlchemy query object. :param url: Database name in project settings. :param callback: Async function/method that manipulates AlchemyResult object and returns Result. :param xcom: Cross communication object Source code in illuminate/observation/sql.py def __init__ ( self , query : Union [ Select , TextClause ], url : str , / , callback : Callable [[ AlchemyResult , tuple , dict ], Result ], xcom : Optional [ Any ] = None , * args , ** kwargs , ): \"\"\" SQLObservation's __init__ method. :param query: SQLAlchemy query object. :param url: Database name in project settings. :param callback: Async function/method that manipulates AlchemyResult object and returns Result. :param xcom: Cross communication object \"\"\" super () . __init__ ( url , xcom = xcom ) self . _callback = callback self . query = query","title":"__init__()"},{"location":"support/#illuminate.observation.sql.SQLObservation.__repr__","text":"SQLObservation's repr method. :return: String representation of an instance Source code in illuminate/observation/sql.py def __repr__ ( self ): \"\"\" SQLObservation's __repr__ method. :return: String representation of an instance \"\"\" return ( f 'SQLObservation(\" { self . query } \",\" { self . url } \",' f 'callback=\" { self . _callback } \")' )","title":"__repr__()"},{"location":"support/#illuminate.observation.sql.SQLObservation.observe","text":"Reads data from database, passes response object to a callback and returns None or Result. :return: None or Result Source code in illuminate/observation/sql.py async def observe ( self , session : Type [ AsyncSession ], * args , ** kwargs ) -> Union [ None , Result ]: \"\"\" Reads data from database, passes response object to a callback and returns None or Result. :return: None or Result \"\"\" try : async with session () as session : # type: ignore async with session . begin (): # type: ignore query = self . query response = await session . execute ( query ) # type: ignore logger . info ( f ' { self } .observe(session=\" { session } \")' ) return self . _callback ( response , * args , ** kwargs ) except Exception as exception : logger . warning ( f \" { self } .observe() -> { exception } \" ) return None","title":"observe()"},{"location":"support/#illuminate.observation.http.SplashObservation","text":"SplashObservation class, reads data from HTTP server asynchronously. Inherits HTTPObservation class and implements observe method. Constructor's kwargs are used to create Splash service URL. For full list of parameters visit https://splash.readthedocs.io/en/stable/api.html. Note: URL is passed as positional argument. It will be used as param in Splash service URL. Source code in illuminate/observation/http.py class SplashObservation ( HTTPObservation ): \"\"\" SplashObservation class, reads data from HTTP server asynchronously. Inherits HTTPObservation class and implements observe method. Constructor's kwargs are used to create Splash service URL. For full list of parameters visit https://splash.readthedocs.io/en/stable/api.html. Note: URL is passed as positional argument. It will be used as param in Splash service URL. \"\"\" def __hash__ ( self ) -> int : \"\"\" SplashObservation object hash value. :return: int \"\"\" return hash ( self . service ) @property def service ( self ): \"\"\" Constructs URL of Splash service :return: Splash URL string \"\"\" defaults : dict = { \"host\" : \"localhost\" , \"port\" : 8050 , \"protocol\" : \"http\" , \"render\" : \"html\" , } parameters = copy ( self . configuration ) for i in defaults : if i in parameters : defaults [ i ] = parameters [ i ] del parameters [ i ] parameters [ \"url\" ] = self . url endpoint = \" {protocol} :// {host} : {port} /render. {render} ?\" endpoint = endpoint . format ( ** defaults ) parameters = urllib . parse . urlencode ( parameters ) return f \" { endpoint . format ( ** defaults ) }{ parameters } \" async def observe ( self , configuration : dict , * args , ** kwargs ) -> Union [ None , Result ]: \"\"\" Requests data from HTTP server and renders response with Splash, passes response object to a callback and returns None or Result. :param configuration: HTTP configuration dict from settings.py :return: None or Result \"\"\" try : response = await httpclient . AsyncHTTPClient () . fetch ( self . service , ** configuration ) logger . info ( f \" { self } .observe() -> { response } \" ) return self . _callback ( response , * args , ** kwargs ) except Exception as exception : logger . warning ( f \" { self } .observe() -> { exception } \" ) return None def __repr__ ( self ): \"\"\" SplashObservation's __repr__ method. :return: String representation of an instance \"\"\" return f 'SplashObservation(\" { self . url } \",callback=\" { self . _callback } \")'","title":"SplashObservation"},{"location":"support/#illuminate.observation.http.SplashObservation.service","text":"Constructs URL of Splash service :return: Splash URL string","title":"service"},{"location":"support/#illuminate.observation.http.SplashObservation.__hash__","text":"SplashObservation object hash value. :return: int Source code in illuminate/observation/http.py def __hash__ ( self ) -> int : \"\"\" SplashObservation object hash value. :return: int \"\"\" return hash ( self . service )","title":"__hash__()"},{"location":"support/#illuminate.observation.http.SplashObservation.__repr__","text":"SplashObservation's repr method. :return: String representation of an instance Source code in illuminate/observation/http.py def __repr__ ( self ): \"\"\" SplashObservation's __repr__ method. :return: String representation of an instance \"\"\" return f 'SplashObservation(\" { self . url } \",callback=\" { self . _callback } \")'","title":"__repr__()"},{"location":"support/#illuminate.observation.http.SplashObservation.observe","text":"Requests data from HTTP server and renders response with Splash, passes response object to a callback and returns None or Result. :param configuration: HTTP configuration dict from settings.py :return: None or Result Source code in illuminate/observation/http.py async def observe ( self , configuration : dict , * args , ** kwargs ) -> Union [ None , Result ]: \"\"\" Requests data from HTTP server and renders response with Splash, passes response object to a callback and returns None or Result. :param configuration: HTTP configuration dict from settings.py :return: None or Result \"\"\" try : response = await httpclient . AsyncHTTPClient () . fetch ( self . service , ** configuration ) logger . info ( f \" { self } .observe() -> { response } \" ) return self . _callback ( response , * args , ** kwargs ) except Exception as exception : logger . warning ( f \" { self } .observe() -> { exception } \" ) return None","title":"observe()"},{"location":"support/#illuminate.observer.finding.Finding","text":"Finding class, contains data that will be passed to Adapter object's adapt method. Source code in illuminate/observer/finding.py class Finding ( IFinding ): \"\"\" Finding class, contains data that will be passed to Adapter object's adapt method. \"\"\"","title":"Finding"},{"location":"support/#illuminate.adapter.adapter.Adapter","text":"Adapter class, generates Exporter and Observation objects using Finding instances with optional transformation. Class must be inherited and method adapt must be implemented in a child class. Source code in illuminate/adapter/adapter.py class Adapter ( IAdapter ): \"\"\" Adapter class, generates Exporter and Observation objects using Finding instances with optional transformation. Class must be inherited and method adapt must be implemented in a child class. \"\"\" priority : int \"\"\" Place in Adapter list. If two Adapters have the same Finding in subscriber tuple, one with the higher priority will call method adapt first on Finding object. \"\"\" subscribers : tuple [ Type [ Finding ]] \"\"\" Tuple of Finding class children used to determent if Adapter object should call method adapt on Finding instance. \"\"\" def __init__ ( self , manager : Optional [ Manager ] = None ): \"\"\" Adapter's __init__ method. :param manager: Manager object \"\"\" self . manager = manager async def adapt ( self , finding : Finding , * args , ** kwargs ) -> AsyncGenerator [ Union [ Exporter , Observation ], None ]: \"\"\" Generates Exporter and Observation objects. Must be implemented in a child class. It is meant to be a scope where additional transformation up on finding objects should be performed (like data enrichment from additional data source) before yielding Exporter or Observation instances. :param finding: Finding object :return: Async Exporter and Observation object generator :raises BasicAdapterException: \"\"\" raise BasicAdapterException ( \"Method adapt must be implemented in child class\" )","title":"Adapter"},{"location":"support/#illuminate.adapter.adapter.Adapter.__init__","text":"Adapter's init method. :param manager: Manager object Source code in illuminate/adapter/adapter.py def __init__ ( self , manager : Optional [ Manager ] = None ): \"\"\" Adapter's __init__ method. :param manager: Manager object \"\"\" self . manager = manager","title":"__init__()"},{"location":"support/#illuminate.adapter.adapter.Adapter.adapt","text":"Generates Exporter and Observation objects. Must be implemented in a child class. It is meant to be a scope where additional transformation up on finding objects should be performed (like data enrichment from additional data source) before yielding Exporter or Observation instances. :param finding: Finding object :return: Async Exporter and Observation object generator :raises BasicAdapterException: Source code in illuminate/adapter/adapter.py async def adapt ( self , finding : Finding , * args , ** kwargs ) -> AsyncGenerator [ Union [ Exporter , Observation ], None ]: \"\"\" Generates Exporter and Observation objects. Must be implemented in a child class. It is meant to be a scope where additional transformation up on finding objects should be performed (like data enrichment from additional data source) before yielding Exporter or Observation instances. :param finding: Finding object :return: Async Exporter and Observation object generator :raises BasicAdapterException: \"\"\" raise BasicAdapterException ( \"Method adapt must be implemented in child class\" )","title":"adapt()"},{"location":"support/#illuminate.exporter.exporter.Exporter","text":"Exporter class, writes data to destination. Class must be inherited and method export must be implemented in a child class. Source code in illuminate/exporter/exporter.py class Exporter ( IExporter ): \"\"\" Exporter class, writes data to destination. Class must be inherited and method export must be implemented in a child class. \"\"\" async def export ( self , * args , ** kwargs ): \"\"\" Writes data to destination. Must be implemented in a child class. :return: None :raises BasicExporterException: \"\"\" raise BasicExporterException ( \"Method export must be implemented in child class\" )","title":"Exporter"},{"location":"support/#illuminate.exporter.exporter.Exporter.export","text":"Writes data to destination. Must be implemented in a child class. :return: None :raises BasicExporterException: Source code in illuminate/exporter/exporter.py async def export ( self , * args , ** kwargs ): \"\"\" Writes data to destination. Must be implemented in a child class. :return: None :raises BasicExporterException: \"\"\" raise BasicExporterException ( \"Method export must be implemented in child class\" )","title":"export()"},{"location":"support/#illuminate.exporter.influxdb.InfluxDBExporter","text":"InfluxDBExporter class, writes data to InfluxDB database asynchronously. Inherits Exporter class and implements export method. Each InfluxDBExporter object is responsible for a single transaction with a single database. Attribute name is used to acquire database session object from Manager's sessions attribute. Constructor kwargs will be passed to client write method. For more information on write method, visit: https://aioinflux.readthedocs.io/en/stable/api.html Supported write data objects: - DataFrame with DatetimeIndex - Dict containing the keys: measurement, time, tags, fields - String (str or bytes) properly formatted in InfluxDB\u2019s line protocol - An iterable of one of the above Source code in illuminate/exporter/influxdb.py class InfluxDBExporter ( Exporter ): \"\"\" InfluxDBExporter class, writes data to InfluxDB database asynchronously. Inherits Exporter class and implements export method. Each InfluxDBExporter object is responsible for a single transaction with a single database. Attribute name is used to acquire database session object from Manager's sessions attribute. Constructor kwargs will be passed to client write method. For more information on write method, visit: https://aioinflux.readthedocs.io/en/stable/api.html Supported write data objects: - DataFrame with DatetimeIndex - Dict containing the keys: measurement, time, tags, fields - String (str or bytes) properly formatted in InfluxDB\u2019s line protocol - An iterable of one of the above \"\"\" name : str \"\"\" InfluxDB database name selector used to get database session object from Manager.sessions attribute. \"\"\" def __init__ ( self , points : Union [ Union [ DataFrame , dict , str , bytes ], Iterable [ Union [ DataFrame , dict , str , bytes ]], ], * args , ** kwargs , ): \"\"\" InfluxDBExporter's __init__ method. :param points: Supported data objects \"\"\" self . params = kwargs self . points = points async def export ( self , session : InfluxDBClient , * args , ** kwargs ) -> None : \"\"\" Writes data to Influxdb asynchronously. :param session: InfluxDBClient object :return: None :raises BasicExporterException: \"\"\" try : await session . write ( self . points , ** self . params ) except Exception as exception : logger . warning ( f ' { self } .export(session=\" { session } \") -> { exception } ' ) raise BasicExporterException logger . success ( f ' { self } .export(session=\" { session } \")' ) def __repr__ ( self ): \"\"\" InfluxDBExporter's __repr__ method. :return: String representation of an instance \"\"\" return f \"InfluxDBExporter(points= { self . points } )\"","title":"InfluxDBExporter"},{"location":"support/#illuminate.exporter.influxdb.InfluxDBExporter.__init__","text":"InfluxDBExporter's init method. :param points: Supported data objects Source code in illuminate/exporter/influxdb.py def __init__ ( self , points : Union [ Union [ DataFrame , dict , str , bytes ], Iterable [ Union [ DataFrame , dict , str , bytes ]], ], * args , ** kwargs , ): \"\"\" InfluxDBExporter's __init__ method. :param points: Supported data objects \"\"\" self . params = kwargs self . points = points","title":"__init__()"},{"location":"support/#illuminate.exporter.influxdb.InfluxDBExporter.__repr__","text":"InfluxDBExporter's repr method. :return: String representation of an instance Source code in illuminate/exporter/influxdb.py def __repr__ ( self ): \"\"\" InfluxDBExporter's __repr__ method. :return: String representation of an instance \"\"\" return f \"InfluxDBExporter(points= { self . points } )\"","title":"__repr__()"},{"location":"support/#illuminate.exporter.influxdb.InfluxDBExporter.export","text":"Writes data to Influxdb asynchronously. :param session: InfluxDBClient object :return: None :raises BasicExporterException: Source code in illuminate/exporter/influxdb.py async def export ( self , session : InfluxDBClient , * args , ** kwargs ) -> None : \"\"\" Writes data to Influxdb asynchronously. :param session: InfluxDBClient object :return: None :raises BasicExporterException: \"\"\" try : await session . write ( self . points , ** self . params ) except Exception as exception : logger . warning ( f ' { self } .export(session=\" { session } \") -> { exception } ' ) raise BasicExporterException logger . success ( f ' { self } .export(session=\" { session } \")' )","title":"export()"},{"location":"support/#illuminate.exporter.sql.SQLExporter","text":"SQLExporter class, writes data to SQL database asynchronously. Inherits Exporter class and implements export method. Each SQLExporter object is responsible for a single transaction with a single database. Attribute name is used to acquire database session object from Manager's sessions attribute. Supported dialects: - Mysql - Postgres Source code in illuminate/exporter/sql.py class SQLExporter ( Exporter ): \"\"\" SQLExporter class, writes data to SQL database asynchronously. Inherits Exporter class and implements export method. Each SQLExporter object is responsible for a single transaction with a single database. Attribute name is used to acquire database session object from Manager's sessions attribute. Supported dialects: - Mysql - Postgres \"\"\" name : str \"\"\" SQL database name selector used to get database session object from Manager.sessions attribute. \"\"\" def __init__ ( self , models : Union [ list [ M ], tuple [ M ]]): \"\"\" SQLExporter's __init__ method. :param models: SQLAlchemy model objects collection \"\"\" self . models = models async def export ( self , session : Type [ AsyncSession ], * args , ** kwargs ) -> None : \"\"\" Writes data to SQL database asynchronously. :param session: AsyncSession object :return: None :raises BasicExporterException: \"\"\" async with session () as session : # type: ignore async with session . begin (): # type: ignore session . add_all ( self . models ) # type: ignore try : await session . commit () # type: ignore except Exception as exception : logger . warning ( f ' { self } .export(session=\" { session } \") -> { exception } ' ) raise BasicExporterException logger . success ( f ' { self } .export(session=\" { session } \")' ) def __repr__ ( self ): \"\"\" SQLExporter's __repr__ method. :return: String representation of an instance \"\"\" return f \"SQLExporter(models= { self . models } )\"","title":"SQLExporter"},{"location":"support/#illuminate.exporter.sql.SQLExporter.__init__","text":"SQLExporter's init method. :param models: SQLAlchemy model objects collection Source code in illuminate/exporter/sql.py def __init__ ( self , models : Union [ list [ M ], tuple [ M ]]): \"\"\" SQLExporter's __init__ method. :param models: SQLAlchemy model objects collection \"\"\" self . models = models","title":"__init__()"},{"location":"support/#illuminate.exporter.sql.SQLExporter.__repr__","text":"SQLExporter's repr method. :return: String representation of an instance Source code in illuminate/exporter/sql.py def __repr__ ( self ): \"\"\" SQLExporter's __repr__ method. :return: String representation of an instance \"\"\" return f \"SQLExporter(models= { self . models } )\"","title":"__repr__()"},{"location":"support/#illuminate.exporter.sql.SQLExporter.export","text":"Writes data to SQL database asynchronously. :param session: AsyncSession object :return: None :raises BasicExporterException: Source code in illuminate/exporter/sql.py async def export ( self , session : Type [ AsyncSession ], * args , ** kwargs ) -> None : \"\"\" Writes data to SQL database asynchronously. :param session: AsyncSession object :return: None :raises BasicExporterException: \"\"\" async with session () as session : # type: ignore async with session . begin (): # type: ignore session . add_all ( self . models ) # type: ignore try : await session . commit () # type: ignore except Exception as exception : logger . warning ( f ' { self } .export(session=\" { session } \") -> { exception } ' ) raise BasicExporterException logger . success ( f ' { self } .export(session=\" { session } \")' )","title":"export()"}]}